{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01adecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "parent = Path(os.path.abspath(\"\")).resolve().parents[0]\n",
    "if parent not in sys.path:\n",
    "    sys.path.insert(0, str(parent))\n",
    "    \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from ml.utils.metrics import get_classification_metrics, get_probability_measures, get_lift_demotion_scores, find_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c0532f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_strings_and_integers(val):\n",
    "    try:\n",
    "        return int(val)\n",
    "    except:\n",
    "        return 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccb2931f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3950/3053899110.py:1: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"final_autof.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT(consumptions)</th>\n",
       "      <th>MAX(consumptions.CSS_MS_HS_USE)</th>\n",
       "      <th>MEAN(consumptions.CSS_MS_HS_USE)</th>\n",
       "      <th>MIN(consumptions.CSS_MS_HS_USE)</th>\n",
       "      <th>NUM_UNIQUE(consumptions.BS_RATE)</th>\n",
       "      <th>NUM_UNIQUE(consumptions.MS_METER_NBR)</th>\n",
       "      <th>SKEW(consumptions.CSS_MS_HS_USE)</th>\n",
       "      <th>STD(consumptions.CSS_MS_HS_USE)</th>\n",
       "      <th>SUM(consumptions.CSS_MS_HS_USE)</th>\n",
       "      <th>MODE(consumptions.DAY(MEASUREMENT_DATE))</th>\n",
       "      <th>...</th>\n",
       "      <th>MODE(consumptions.BS_RATE)_40</th>\n",
       "      <th>MODE(consumptions.BS_RATE)_41</th>\n",
       "      <th>MODE(consumptions.BS_RATE)_42</th>\n",
       "      <th>MODE(consumptions.BS_RATE)_43</th>\n",
       "      <th>MODE(consumptions.BS_RATE)_44</th>\n",
       "      <th>MODE(consumptions.BS_RATE)_52</th>\n",
       "      <th>MODE(consumptions.BS_RATE)_53</th>\n",
       "      <th>MODE(consumptions.BS_RATE)_54</th>\n",
       "      <th>MODE(consumptions.BS_RATE)_55</th>\n",
       "      <th>MODE(consumptions.BS_RATE)_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>64.250000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.758461</td>\n",
       "      <td>54.389797</td>\n",
       "      <td>257.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>51.900000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.783315</td>\n",
       "      <td>43.072162</td>\n",
       "      <td>519.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>6068.0</td>\n",
       "      <td>3924.166667</td>\n",
       "      <td>2446.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.574519</td>\n",
       "      <td>1012.516472</td>\n",
       "      <td>47090.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1061.0</td>\n",
       "      <td>479.333333</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020392</td>\n",
       "      <td>409.340282</td>\n",
       "      <td>2876.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>1247.0</td>\n",
       "      <td>536.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.537625</td>\n",
       "      <td>335.364392</td>\n",
       "      <td>12884.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   COUNT(consumptions)  MAX(consumptions.CSS_MS_HS_USE)  \\\n",
       "0                  4.0                            135.0   \n",
       "1                 10.0                            127.0   \n",
       "2                 12.0                           6068.0   \n",
       "3                  6.0                           1061.0   \n",
       "4                 24.0                           1247.0   \n",
       "\n",
       "   MEAN(consumptions.CSS_MS_HS_USE)  MIN(consumptions.CSS_MS_HS_USE)  \\\n",
       "0                         64.250000                             12.0   \n",
       "1                         51.900000                              0.0   \n",
       "2                       3924.166667                           2446.0   \n",
       "3                        479.333333                              7.0   \n",
       "4                        536.833333                              0.0   \n",
       "\n",
       "   NUM_UNIQUE(consumptions.BS_RATE)  NUM_UNIQUE(consumptions.MS_METER_NBR)  \\\n",
       "0                               1.0                                    1.0   \n",
       "1                               1.0                                    2.0   \n",
       "2                               1.0                                    1.0   \n",
       "3                               2.0                                    1.0   \n",
       "4                               2.0                                    1.0   \n",
       "\n",
       "   SKEW(consumptions.CSS_MS_HS_USE)  STD(consumptions.CSS_MS_HS_USE)  \\\n",
       "0                          0.758461                        54.389797   \n",
       "1                          0.783315                        43.072162   \n",
       "2                          0.574519                      1012.516472   \n",
       "3                          0.020392                       409.340282   \n",
       "4                          0.537625                       335.364392   \n",
       "\n",
       "   SUM(consumptions.CSS_MS_HS_USE)  MODE(consumptions.DAY(MEASUREMENT_DATE))  \\\n",
       "0                            257.0                                       2.0   \n",
       "1                            519.0                                       2.0   \n",
       "2                          47090.0                                      28.0   \n",
       "3                           2876.0                                       4.0   \n",
       "4                          12884.0                                       4.0   \n",
       "\n",
       "   ...  MODE(consumptions.BS_RATE)_40  MODE(consumptions.BS_RATE)_41  \\\n",
       "0  ...                              0                              0   \n",
       "1  ...                              0                              0   \n",
       "2  ...                              0                              0   \n",
       "3  ...                              0                              0   \n",
       "4  ...                              0                              0   \n",
       "\n",
       "   MODE(consumptions.BS_RATE)_42  MODE(consumptions.BS_RATE)_43  \\\n",
       "0                              0                              0   \n",
       "1                              0                              0   \n",
       "2                              0                              0   \n",
       "3                              0                              0   \n",
       "4                              0                              0   \n",
       "\n",
       "   MODE(consumptions.BS_RATE)_44  MODE(consumptions.BS_RATE)_52  \\\n",
       "0                              0                              0   \n",
       "1                              0                              0   \n",
       "2                              0                              0   \n",
       "3                              0                              0   \n",
       "4                              0                              0   \n",
       "\n",
       "   MODE(consumptions.BS_RATE)_53  MODE(consumptions.BS_RATE)_54  \\\n",
       "0                              0                              0   \n",
       "1                              0                              0   \n",
       "2                              0                              0   \n",
       "3                              0                              0   \n",
       "4                              0                              0   \n",
       "\n",
       "   MODE(consumptions.BS_RATE)_55  MODE(consumptions.BS_RATE)_other  \n",
       "0                              0                                 0  \n",
       "1                              0                                 0  \n",
       "2                              0                                 0  \n",
       "3                              0                                 0  \n",
       "4                              0                                 0  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"final_autof.csv\")\n",
    "df.drop([\n",
    "    'MODE(consumptions.MS_METER_NBR)',\n",
    "    'MODE(representations.SUPPLIER)',\n",
    "    'MODE(representations.SUPPLIER_TO)',\n",
    "], axis=1, inplace=True)\n",
    "df.dropna(subset=['number_of_zeros'], inplace=True)\n",
    "\n",
    "\n",
    "df['MODE(consumptions.BS_RATE)'] = df['MODE(consumptions.BS_RATE)'].apply(merge_strings_and_integers)\n",
    "df = df.drop(['rec_id'], axis=1)\n",
    "df = df.drop_duplicates()\n",
    "df['MODE(requests.REQUEST_TYPE)'] = df['MODE(requests.REQUEST_TYPE)'].replace(0, 'unknown')\n",
    "df = pd.get_dummies(df, columns=['MODE(requests.REQUEST_TYPE)'], prefix='MODE(requests.REQUEST_TYPE)')\n",
    "df = pd.get_dummies(df, columns=['MODE(consumptions.BS_RATE)'], prefix='MODE(consumptions.BS_RATE)')\n",
    "df = df.drop(['voltage'], axis=1)\n",
    "df.fillna(0, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "039c7085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y):\n",
    "    \n",
    "    \n",
    "    classifiers = {\n",
    "        #\"GaussianNB\": GaussianNB(),\n",
    "        #\"BernoulliNB\": GaussianNB(),\n",
    "        #\"MultinomialNB\": MultinomialNB(),\n",
    "        \"KNN\": KNeighborsClassifier(),\n",
    "        \"DT\": DecisionTreeClassifier(random_state=0),\n",
    "        \"RF\": RandomForestClassifier(random_state=0),\n",
    "        \"LR\": LogisticRegression(random_state=0),\n",
    "        \"XGB\": XGBClassifier(random_state=0),\n",
    "        \"CatBoost\": CatBoostClassifier(random_state=0) \n",
    "    }\n",
    "    averaged_scores = dict()\n",
    "    \n",
    "    print(\"Number of samples:\", len(X))\n",
    "    print(\"Data bins:\", np.bincount(y))\n",
    "    \n",
    "    for clf_name, clf in classifiers.items():\n",
    "        \n",
    "        print(\"Classifier:\", clf_name)\n",
    "        assert len(X) == len(y)\n",
    "        scaler = MinMaxScaler()\n",
    "\n",
    "        acc_scores = []\n",
    "        prec_scores = []\n",
    "        rec_scores = []\n",
    "        f1_scores = []\n",
    "        brier_scores, auc_roc_scores, pr_auc_scores = [], [], []\n",
    "        lift_scores1, demotion_scores1, weighted_scores1 = [], [], []\n",
    "        lift_scores2, demotion_scores2, weighted_scores2 = [], [], []\n",
    "        lift_scores3, demotion_scores3, weighted_scores3 = [], [], []\n",
    "        lift_scores4, demotion_scores4, weighted_scores4 = [], [], []\n",
    "        lift_scores5, demotion_scores5, weighted_scores5 = [], [], []\n",
    "        lift_scores6, demotion_scores6, weighted_scores6 = [], [], []\n",
    "        lift_scores7, demotion_scores7, weighted_scores7 = [], [], []\n",
    "        lift_scores8, demotion_scores8, weighted_scores8 = [], [], []\n",
    "        lift_scores9, demotion_scores9, weighted_scores9 = [], [], []\n",
    "        lift_scores10, demotion_scores10, weighted_scores10 = [], [], []\n",
    "\n",
    "\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            scaler.fit(X_train)\n",
    "            X_train = scaler.transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "\n",
    "            #print(\"Shape\", X_train.shape)\n",
    "\n",
    "\n",
    "            #print(\"bins train\", np.bincount(y_train))\n",
    "            #print(\"bins test\", np.bincount(y_test))\n",
    "\n",
    "            if clf_name == \"CatBoost\":\n",
    "                clf.fit(X_train, y_train, verbose=False)\n",
    "            else:\n",
    "                clf.fit(X_train, y_train)\n",
    "\n",
    "            y_pred = clf.predict(X_test)\n",
    "\n",
    "            acc, precision, recall, f1 = get_classification_metrics(y_test.values, y_pred)\n",
    "\n",
    "            y_scores = clf.predict_proba(X_test)\n",
    "            idx = np.argmax(y_scores, axis=1)\n",
    "            y_scores = np.where(idx == 0, 1 - y_scores[:, 0], y_scores[:, 1])\n",
    "\n",
    "\n",
    "            brier, roc_auc, pr_auc = get_probability_measures(y_test.values, y_scores)\n",
    "\n",
    "            num_ones = np.sum(y_test == 1)\n",
    "            \n",
    "            print(\"HOW\", num_ones)\n",
    "\n",
    "\n",
    "            s1 = int(0.1 * num_ones)\n",
    "            s2 = int(0.2 * num_ones)\n",
    "            s3 = int(0.3 * num_ones)\n",
    "            s4 = int(0.4 * num_ones)\n",
    "            s5 = int(0.5 * num_ones)\n",
    "            s6 = int(0.6 * num_ones)\n",
    "            s7 = int(0.7 * num_ones)\n",
    "            s8 = int(0.8 * num_ones)\n",
    "            s9 = int(0.9 * num_ones)\n",
    "            s10 = int(1 * num_ones)\n",
    "\n",
    "            lift1, demotion1, weighted_score1 = get_lift_demotion_scores(y_test.values, y_scores,\n",
    "                                                                        num_samples=s1)\n",
    "            lift2, demotion2, weighted_score2 = get_lift_demotion_scores(y_test.values, y_scores,\n",
    "                                                                        num_samples=s2)\n",
    "            lift3, demotion3, weighted_score3 = get_lift_demotion_scores(y_test.values, y_scores,\n",
    "                                                                        num_samples=s3)\n",
    "            lift4, demotion4, weighted_score4 = get_lift_demotion_scores(y_test.values, y_scores,\n",
    "                                                                        num_samples=s4)\n",
    "            lift5, demotion5, weighted_score5 = get_lift_demotion_scores(y_test.values, y_scores,\n",
    "                                                                        num_samples=s5)\n",
    "            lift6, demotion6, weighted_score6 = get_lift_demotion_scores(y_test.values, y_scores,\n",
    "                                                                        num_samples=s6)\n",
    "            lift7, demotion7, weighted_score7 = get_lift_demotion_scores(y_test.values, y_scores,\n",
    "                                                                        num_samples=s7)\n",
    "            lift8, demotion8, weighted_score8 = get_lift_demotion_scores(y_test.values, y_scores,\n",
    "                                                                        num_samples=s8)\n",
    "            lift9, demotion9, weighted_score9 = get_lift_demotion_scores(y_test.values, y_scores,\n",
    "                                                                        num_samples=s9)\n",
    "            lift10, demotion10, weighted_score10 = get_lift_demotion_scores(y_test.values, y_scores,\n",
    "                                                                        num_samples=s10)\n",
    "\n",
    "            acc_scores.append(acc)\n",
    "            prec_scores.append(precision)\n",
    "            rec_scores.append(recall)\n",
    "            f1_scores.append(f1)\n",
    "\n",
    "            brier_scores.append(brier)\n",
    "            auc_roc_scores.append(roc_auc)\n",
    "            pr_auc_scores.append(pr_auc)\n",
    "\n",
    "            lift_scores1.append(lift1)\n",
    "            demotion_scores1.append(demotion1)\n",
    "            weighted_scores1.append(weighted_score1)\n",
    "            lift_scores2.append(lift2)\n",
    "            demotion_scores2.append(demotion2)\n",
    "            weighted_scores2.append(weighted_score2)\n",
    "            lift_scores3.append(lift3)\n",
    "            demotion_scores3.append(demotion3)\n",
    "            weighted_scores3.append(weighted_score3)\n",
    "            lift_scores4.append(lift4)\n",
    "            demotion_scores4.append(demotion4)\n",
    "            weighted_scores4.append(weighted_score4)\n",
    "            lift_scores5.append(lift5)\n",
    "            demotion_scores5.append(demotion5)\n",
    "            weighted_scores5.append(weighted_score5)\n",
    "            lift_scores6.append(lift6)\n",
    "            demotion_scores6.append(demotion6)\n",
    "            weighted_scores6.append(weighted_score6)\n",
    "            lift_scores7.append(lift7)\n",
    "            demotion_scores7.append(demotion7)\n",
    "            weighted_scores7.append(weighted_score7)\n",
    "            lift_scores8.append(lift8)\n",
    "            demotion_scores8.append(demotion8)\n",
    "            weighted_scores8.append(weighted_score8)\n",
    "            lift_scores9.append(lift9)\n",
    "            demotion_scores9.append(demotion9)\n",
    "            weighted_scores9.append(weighted_score9)\n",
    "            lift_scores10.append(lift10)\n",
    "            demotion_scores10.append(demotion10)\n",
    "            weighted_scores10.append(weighted_score10)\n",
    "            \n",
    "\n",
    "        averaged_scores[clf_name] = dict()\n",
    "        \n",
    "        acc, prec, rec = sum(acc_scores)/len(acc_scores), sum(prec_scores)/len(prec_scores), sum(rec_scores)/len(rec_scores) \n",
    "        acc_std, prec_std, rec_std = np.std(acc_scores), np.std(prec_scores), np.std(rec_scores)\n",
    "        averaged_scores[clf_name]['Accuracy'] = acc\n",
    "        averaged_scores[clf_name]['Accuracy_std'] = acc_std\n",
    "        averaged_scores[clf_name]['Precision'] = prec\n",
    "        averaged_scores[clf_name]['Precision_std'] = prec_std\n",
    "        averaged_scores[clf_name]['Recall'] = rec\n",
    "        averaged_scores[clf_name]['Recall_std'] = rec_std\n",
    "        \n",
    "        f1, brier, auc_roc, pr_auc = sum(f1_scores)/len(f1_scores), sum(brier_scores)/len(brier_scores), sum(auc_roc_scores)/len(auc_roc_scores), sum(pr_auc_scores)/len(pr_auc_scores)\n",
    "        f1_std, brier_std, auc_roc_std, pr_auc_std = np.std(f1_scores), np.std(brier_scores), np.std(auc_roc_scores), np.std(pr_auc_scores)\n",
    "        averaged_scores[clf_name]['F1'] = f1\n",
    "        averaged_scores[clf_name]['F1_std'] = f1_std\n",
    "        averaged_scores[clf_name]['Brier'] = brier\n",
    "        averaged_scores[clf_name]['Brier_std'] = brier_std\n",
    "        averaged_scores[clf_name]['AUC-ROC'] = auc_roc\n",
    "        averaged_scores[clf_name]['AUC-ROC_std'] = auc_roc_std\n",
    "        averaged_scores[clf_name]['PR-AUC'] = pr_auc\n",
    "        averaged_scores[clf_name]['PR-AUC_std'] = pr_auc_std\n",
    "        \n",
    "        \n",
    "        lift1, demotion1, weighted_score1 = sum(lift_scores1)/len(lift_scores1), sum(demotion_scores1)/len(demotion_scores1), sum(weighted_scores1)/len(weighted_scores1)\n",
    "        lift1_std, demotion1_std, weighted1_std = np.std(lift_scores1), np.std(demotion_scores1), np.std(weighted_scores1)\n",
    "        \n",
    "        lift2, demotion2, weighted_score2 = sum(lift_scores2)/len(lift_scores2), sum(demotion_scores2)/len(demotion_scores2), sum(weighted_scores2)/len(weighted_scores2)\n",
    "        lift2_std, demotion2_std, weighted2_std = np.std(lift_scores2), np.std(demotion_scores2), np.std(weighted_scores2)\n",
    "\n",
    "        lift3, demotion3, weighted_score3 = sum(lift_scores3)/len(lift_scores3), sum(demotion_scores3)/len(demotion_scores3), sum(weighted_scores3)/len(weighted_scores3)\n",
    "        lift3_std, demotion3_std, weighted3_std = np.std(lift_scores3), np.std(demotion_scores3), np.std(weighted_scores3)\n",
    "        \n",
    "        lift4, demotion4, weighted_score4 = sum(lift_scores4)/len(lift_scores4), sum(demotion_scores4)/len(demotion_scores4), sum(weighted_scores4)/len(weighted_scores4)\n",
    "        lift4_std, demotion4_std, weighted4_std = np.std(lift_scores4), np.std(demotion_scores4), np.std(weighted_scores4)\n",
    "        \n",
    "        lift5, demotion5, weighted_score5 = sum(lift_scores5)/len(lift_scores5), sum(demotion_scores5)/len(demotion_scores5), sum(weighted_scores5)/len(weighted_scores5)\n",
    "        lift5_std, demotion5_std, weighted5_std = np.std(lift_scores5), np.std(demotion_scores5), np.std(weighted_scores5)\n",
    "        \n",
    "        lift6, demotion6, weighted_score6 = sum(lift_scores6)/len(lift_scores6), sum(demotion_scores6)/len(demotion_scores6), sum(weighted_scores6)/len(weighted_scores6)\n",
    "        lift6_std, demotion6_std, weighted6_std = np.std(lift_scores6), np.std(demotion_scores6), np.std(weighted_scores6)\n",
    "        \n",
    "        lift7, demotion7, weighted_score7 = sum(lift_scores7)/len(lift_scores7), sum(demotion_scores7)/len(demotion_scores7), sum(weighted_scores7)/len(weighted_scores7)\n",
    "        lift7_std, demotion7_std, weighted7_std = np.std(lift_scores7), np.std(demotion_scores7), np.std(weighted_scores7)\n",
    "        \n",
    "        lift8, demotion8, weighted_score8 = sum(lift_scores8)/len(lift_scores8), sum(demotion_scores8)/len(demotion_scores8), sum(weighted_scores8)/len(weighted_scores8)\n",
    "        lift8_std, demotion8_std, weighted8_std = np.std(lift_scores8), np.std(demotion_scores8), np.std(weighted_scores8)\n",
    "        \n",
    "        lift9, demotion9, weighted_score9 = sum(lift_scores9)/len(lift_scores9), sum(demotion_scores9)/len(demotion_scores9), sum(weighted_scores9)/len(weighted_scores9)\n",
    "        lift9_std, demotion9_std, weighted9_std = np.std(lift_scores9), np.std(demotion_scores9), np.std(weighted_scores9)\n",
    "        \n",
    "        lift10, demotion10, weighted_score10 = sum(lift_scores10)/len(lift_scores10), sum(demotion_scores10)/len(demotion_scores10), sum(weighted_scores10)/len(weighted_scores10)\n",
    "        lift10_std, demotion10_std, weighted10_std = np.std(lift_scores10), np.std(demotion_scores10), np.std(weighted_scores10)\n",
    "        \n",
    "        averaged_scores[clf_name]['Lift1'] = lift1\n",
    "        averaged_scores[clf_name]['Lift1_std'] = lift1_std\n",
    "        averaged_scores[clf_name]['Demotion1'] = demotion1\n",
    "        averaged_scores[clf_name]['Demotion1_std'] = demotion1_std\n",
    "        averaged_scores[clf_name]['Weighted1'] = weighted_score1\n",
    "        averaged_scores[clf_name]['Weighted1_std'] = weighted1_std\n",
    "        \n",
    "        averaged_scores[clf_name]['Lift2'] = lift2\n",
    "        averaged_scores[clf_name]['Lift2_std'] = lift2_std\n",
    "        averaged_scores[clf_name]['Demotion2'] = demotion2\n",
    "        averaged_scores[clf_name]['Demotion2_std'] = demotion2_std\n",
    "        averaged_scores[clf_name]['Weighted2'] = weighted_score2\n",
    "        averaged_scores[clf_name]['Weighted2_std'] = weighted2_std\n",
    "        \n",
    "        averaged_scores[clf_name]['Lift3'] = lift3\n",
    "        averaged_scores[clf_name]['Lift3_std'] = lift3_std\n",
    "        averaged_scores[clf_name]['Demotion3'] = demotion3\n",
    "        averaged_scores[clf_name]['Demotion3_std'] = demotion3_std\n",
    "        averaged_scores[clf_name]['Weighted3'] = weighted_score3\n",
    "        averaged_scores[clf_name]['Weighted3_std'] = weighted3_std\n",
    "        \n",
    "        averaged_scores[clf_name]['Lift4'] = lift4\n",
    "        averaged_scores[clf_name]['Lift4_std'] = lift4_std\n",
    "        averaged_scores[clf_name]['Demotion4'] = demotion4\n",
    "        averaged_scores[clf_name]['Demotion4_std'] = demotion4_std\n",
    "        averaged_scores[clf_name]['Weighted4'] = weighted_score4\n",
    "        averaged_scores[clf_name]['Weighted4_std'] = weighted4_std\n",
    "        \n",
    "        averaged_scores[clf_name]['Lift5'] = lift5\n",
    "        averaged_scores[clf_name]['Lift5_std'] = lift5_std\n",
    "        averaged_scores[clf_name]['Demotion5'] = demotion5\n",
    "        averaged_scores[clf_name]['Demotion5_std'] = demotion5_std\n",
    "        averaged_scores[clf_name]['Weighted5'] = weighted_score5\n",
    "        averaged_scores[clf_name]['Weighted5_std'] = weighted5_std\n",
    "        \n",
    "        averaged_scores[clf_name]['Lift6'] = lift6\n",
    "        averaged_scores[clf_name]['Lift6_std'] = lift6_std\n",
    "        averaged_scores[clf_name]['Demotion6'] = demotion6\n",
    "        averaged_scores[clf_name]['Demotion6_std'] = demotion6_std\n",
    "        averaged_scores[clf_name]['Weighted6'] = weighted_score6\n",
    "        averaged_scores[clf_name]['Weighted6_std'] = weighted6_std\n",
    "        \n",
    "        averaged_scores[clf_name]['Lift7'] = lift7\n",
    "        averaged_scores[clf_name]['Lift7_std'] = lift7_std\n",
    "        averaged_scores[clf_name]['Demotion7'] = demotion7\n",
    "        averaged_scores[clf_name]['Demotion7_std'] = demotion7_std\n",
    "        averaged_scores[clf_name]['Weighted7'] = weighted_score7\n",
    "        averaged_scores[clf_name]['Weighted7_std'] = weighted7_std\n",
    "        \n",
    "        averaged_scores[clf_name]['Lift8'] = lift8\n",
    "        averaged_scores[clf_name]['Lift8_std'] = lift8_std\n",
    "        averaged_scores[clf_name]['Demotion8'] = demotion8\n",
    "        averaged_scores[clf_name]['Demotion8_std'] = demotion8_std\n",
    "        averaged_scores[clf_name]['Weighted8'] = weighted_score8\n",
    "        averaged_scores[clf_name]['Weighted8_std'] = weighted8_std\n",
    "        \n",
    "        averaged_scores[clf_name]['Lift9'] = lift9\n",
    "        averaged_scores[clf_name]['Lift9_std'] = lift9_std\n",
    "        averaged_scores[clf_name]['Demotion9'] = demotion9\n",
    "        averaged_scores[clf_name]['Demotion9_std'] = demotion9_std\n",
    "        averaged_scores[clf_name]['Weighted9'] = weighted_score9\n",
    "        averaged_scores[clf_name]['Weighted9_std'] = weighted9_std\n",
    "        \n",
    "        averaged_scores[clf_name]['Lift10'] = lift10\n",
    "        averaged_scores[clf_name]['Lift10_std'] = lift10_std\n",
    "        averaged_scores[clf_name]['Demotion10'] = demotion10\n",
    "        averaged_scores[clf_name]['Demotion10_std'] = demotion10_std\n",
    "        averaged_scores[clf_name]['Weighted10'] = weighted_score10\n",
    "        averaged_scores[clf_name]['Weighted10_std'] = weighted10_std\n",
    "        \n",
    "        print(\"Average - Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1: {:.4f}, Brier: {:.4f}, AUC-ROC: {:.4f}, PR-AUC: {:.4f}, Lift: {:.4f}, Demotion: {:.4f}, Weighted: {:.4f}\\n\"\n",
    "                .format(sum(acc_scores)/len(acc_scores), sum(prec_scores)/len(prec_scores),\n",
    "                        sum(rec_scores)/len(rec_scores), sum(f1_scores)/len(f1_scores),\n",
    "                        sum(brier_scores)/len(brier_scores), sum(auc_roc_scores)/len(auc_roc_scores), sum(pr_auc_scores)/len(pr_auc_scores),\n",
    "                        sum(lift_scores4)/len(lift_scores4), sum(demotion_scores4)/len(demotion_scores4), sum(weighted_scores4)/len(weighted_scores4)))\n",
    "        print(\"\\n\\n\")\n",
    "    return pd.DataFrame(averaged_scores).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d061b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1d49810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700519\n",
      "700519\n",
      "Number of samples: 700519\n",
      "Data bins: [698967   1552]\n",
      "Classifier: GaussianNB\n",
      "Average - Accuracy: 0.0270, Precision: 0.0022, Recall: 0.9897, F1: 0.0045, Brier: 0.9729, AUC-ROC: 0.5077, PR-AUC: 0.0022, Lift: 0.0016, Demotion: 0.9984, Weighted: 0.3006\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classifier: BernoulliNB\n",
      "Average - Accuracy: 0.0270, Precision: 0.0022, Recall: 0.9897, F1: 0.0045, Brier: 0.9729, AUC-ROC: 0.5077, PR-AUC: 0.0022, Lift: 0.0016, Demotion: 0.9984, Weighted: 0.3006\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classifier: MultinomialNB\n",
      "Average - Accuracy: 0.9977, Precision: 0.0250, Recall: 0.0006, F1: 0.0013, Brier: 0.0023, AUC-ROC: 0.8138, PR-AUC: 0.0106, Lift: 0.0194, Demotion: 1.0000, Weighted: 0.3135\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classifier: DT\n",
      "Average - Accuracy: 0.9952, Precision: 0.0653, Recall: 0.0863, F1: 0.0743, Brier: 0.0048, AUC-ROC: 0.5418, PR-AUC: 0.0077, Lift: 0.0661, Demotion: 1.0000, Weighted: 0.3463\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classifier: RF\n",
      "Average - Accuracy: 0.9978, Precision: 1.0000, Recall: 0.0090, F1: 0.0179, Brier: 0.0021, AUC-ROC: 0.7961, PR-AUC: 0.0952, Lift: 0.2484, Demotion: 1.0000, Weighted: 0.4739\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classifier: LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vasilis/miniconda3/envs/HendoChallenge/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/vasilis/miniconda3/envs/HendoChallenge/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/vasilis/miniconda3/envs/HendoChallenge/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/vasilis/miniconda3/envs/HendoChallenge/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/vasilis/miniconda3/envs/HendoChallenge/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average - Accuracy: 0.9978, Precision: 0.1533, Recall: 0.0026, F1: 0.0051, Brier: 0.0022, AUC-ROC: 0.8671, PR-AUC: 0.0464, Lift: 0.1661, Demotion: 1.0000, Weighted: 0.4163\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classifier: XGB\n",
      "Average - Accuracy: 0.9978, Precision: 0.5883, Recall: 0.0406, F1: 0.0758, Brier: 0.0021, AUC-ROC: 0.8937, PR-AUC: 0.1005, Lift: 0.2548, Demotion: 1.0000, Weighted: 0.4784\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classifier: CatBoost\n",
      "Average - Accuracy: 0.9978, Precision: 0.7208, Recall: 0.0483, F1: 0.0903, Brier: 0.0021, AUC-ROC: 0.8939, PR-AUC: 0.1157, Lift: 0.2903, Demotion: 1.0000, Weighted: 0.5032\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "print(len(df))\n",
    "df = df.drop_duplicates()\n",
    "print(len(df))\n",
    "X = df.drop(['target'], axis=1)\n",
    "y = df['target']\n",
    "results = train(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d435eb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "results = results.sort_values(['Weighted4', 'Weighted4_std'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d89569af",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"classifier_res1.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26e1c986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Accuracy_std</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Precision_std</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Recall_std</th>\n",
       "      <th>F1</th>\n",
       "      <th>F1_std</th>\n",
       "      <th>Brier</th>\n",
       "      <th>Brier_std</th>\n",
       "      <th>AUC-ROC</th>\n",
       "      <th>AUC-ROC_std</th>\n",
       "      <th>PR-AUC</th>\n",
       "      <th>PR-AUC_std</th>\n",
       "      <th>Lift1</th>\n",
       "      <th>Lift1_std</th>\n",
       "      <th>Demotion1</th>\n",
       "      <th>Demotion1_std</th>\n",
       "      <th>Weighted1</th>\n",
       "      <th>Weighted1_std</th>\n",
       "      <th>Lift2</th>\n",
       "      <th>Lift2_std</th>\n",
       "      <th>Demotion2</th>\n",
       "      <th>Demotion2_std</th>\n",
       "      <th>Weighted2</th>\n",
       "      <th>Weighted2_std</th>\n",
       "      <th>Lift3</th>\n",
       "      <th>Lift3_std</th>\n",
       "      <th>Demotion3</th>\n",
       "      <th>Demotion3_std</th>\n",
       "      <th>Weighted3</th>\n",
       "      <th>Weighted3_std</th>\n",
       "      <th>Lift4</th>\n",
       "      <th>Lift4_std</th>\n",
       "      <th>Demotion4</th>\n",
       "      <th>Demotion4_std</th>\n",
       "      <th>Weighted4</th>\n",
       "      <th>Weighted4_std</th>\n",
       "      <th>Lift5</th>\n",
       "      <th>Lift5_std</th>\n",
       "      <th>Demotion5</th>\n",
       "      <th>Demotion5_std</th>\n",
       "      <th>Weighted5</th>\n",
       "      <th>Weighted5_std</th>\n",
       "      <th>Lift6</th>\n",
       "      <th>Lift6_std</th>\n",
       "      <th>Demotion6</th>\n",
       "      <th>Demotion6_std</th>\n",
       "      <th>Weighted6</th>\n",
       "      <th>Weighted6_std</th>\n",
       "      <th>Lift7</th>\n",
       "      <th>Lift7_std</th>\n",
       "      <th>Demotion7</th>\n",
       "      <th>Demotion7_std</th>\n",
       "      <th>Weighted7</th>\n",
       "      <th>Weighted7_std</th>\n",
       "      <th>Lift8</th>\n",
       "      <th>Lift8_std</th>\n",
       "      <th>Demotion8</th>\n",
       "      <th>Demotion8_std</th>\n",
       "      <th>Weighted8</th>\n",
       "      <th>Weighted8_std</th>\n",
       "      <th>Lift9</th>\n",
       "      <th>Lift9_std</th>\n",
       "      <th>Demotion9</th>\n",
       "      <th>Demotion9_std</th>\n",
       "      <th>Weighted9</th>\n",
       "      <th>Weighted9_std</th>\n",
       "      <th>Lift10</th>\n",
       "      <th>Lift10_std</th>\n",
       "      <th>Demotion10</th>\n",
       "      <th>Demotion10_std</th>\n",
       "      <th>Weighted10</th>\n",
       "      <th>Weighted10_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>0.997849</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.720836</td>\n",
       "      <td>0.072434</td>\n",
       "      <td>0.048323</td>\n",
       "      <td>0.009321</td>\n",
       "      <td>0.090337</td>\n",
       "      <td>0.016369</td>\n",
       "      <td>0.002070</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.893919</td>\n",
       "      <td>0.006897</td>\n",
       "      <td>0.115654</td>\n",
       "      <td>0.013396</td>\n",
       "      <td>0.606452</td>\n",
       "      <td>0.065794</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.724516</td>\n",
       "      <td>0.046056</td>\n",
       "      <td>0.409677</td>\n",
       "      <td>0.038978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.586774</td>\n",
       "      <td>0.027284</td>\n",
       "      <td>0.337634</td>\n",
       "      <td>0.033037</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.536344</td>\n",
       "      <td>0.023126</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.027467</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.503226</td>\n",
       "      <td>0.019227</td>\n",
       "      <td>0.256774</td>\n",
       "      <td>0.026569</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.479742</td>\n",
       "      <td>0.018599</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.028449</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.458065</td>\n",
       "      <td>0.019914</td>\n",
       "      <td>0.208295</td>\n",
       "      <td>0.026776</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.445806</td>\n",
       "      <td>0.018743</td>\n",
       "      <td>0.195968</td>\n",
       "      <td>0.024140</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.437177</td>\n",
       "      <td>0.016898</td>\n",
       "      <td>0.182079</td>\n",
       "      <td>0.021071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.427455</td>\n",
       "      <td>0.014750</td>\n",
       "      <td>0.168200</td>\n",
       "      <td>0.020452</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.417740</td>\n",
       "      <td>0.014317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <td>0.997812</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.588264</td>\n",
       "      <td>0.081948</td>\n",
       "      <td>0.040591</td>\n",
       "      <td>0.008551</td>\n",
       "      <td>0.075843</td>\n",
       "      <td>0.015521</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.893664</td>\n",
       "      <td>0.005076</td>\n",
       "      <td>0.100469</td>\n",
       "      <td>0.018125</td>\n",
       "      <td>0.509677</td>\n",
       "      <td>0.087514</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.656774</td>\n",
       "      <td>0.061260</td>\n",
       "      <td>0.390323</td>\n",
       "      <td>0.065635</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573226</td>\n",
       "      <td>0.045945</td>\n",
       "      <td>0.303226</td>\n",
       "      <td>0.043225</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.512258</td>\n",
       "      <td>0.030258</td>\n",
       "      <td>0.254839</td>\n",
       "      <td>0.038710</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.478387</td>\n",
       "      <td>0.027097</td>\n",
       "      <td>0.229677</td>\n",
       "      <td>0.032796</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460774</td>\n",
       "      <td>0.022957</td>\n",
       "      <td>0.204301</td>\n",
       "      <td>0.023558</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.443011</td>\n",
       "      <td>0.016491</td>\n",
       "      <td>0.188018</td>\n",
       "      <td>0.023207</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.431613</td>\n",
       "      <td>0.016245</td>\n",
       "      <td>0.174194</td>\n",
       "      <td>0.019983</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.421935</td>\n",
       "      <td>0.013988</td>\n",
       "      <td>0.164875</td>\n",
       "      <td>0.018276</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.415412</td>\n",
       "      <td>0.012793</td>\n",
       "      <td>0.157878</td>\n",
       "      <td>0.012438</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.410514</td>\n",
       "      <td>0.008707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.997804</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009022</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>0.017879</td>\n",
       "      <td>0.002550</td>\n",
       "      <td>0.002115</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.796100</td>\n",
       "      <td>0.011823</td>\n",
       "      <td>0.095216</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.079016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.055311</td>\n",
       "      <td>0.351613</td>\n",
       "      <td>0.044930</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.546129</td>\n",
       "      <td>0.031451</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.024520</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.503226</td>\n",
       "      <td>0.017164</td>\n",
       "      <td>0.248387</td>\n",
       "      <td>0.021878</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.473871</td>\n",
       "      <td>0.015315</td>\n",
       "      <td>0.230968</td>\n",
       "      <td>0.023932</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.461677</td>\n",
       "      <td>0.016752</td>\n",
       "      <td>0.205376</td>\n",
       "      <td>0.017471</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.443763</td>\n",
       "      <td>0.012230</td>\n",
       "      <td>0.188018</td>\n",
       "      <td>0.011437</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.431613</td>\n",
       "      <td>0.008006</td>\n",
       "      <td>0.175806</td>\n",
       "      <td>0.010999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.423065</td>\n",
       "      <td>0.007699</td>\n",
       "      <td>0.163441</td>\n",
       "      <td>0.014968</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.414409</td>\n",
       "      <td>0.010478</td>\n",
       "      <td>0.154656</td>\n",
       "      <td>0.014872</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.408259</td>\n",
       "      <td>0.010410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.997762</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.153333</td>\n",
       "      <td>0.232475</td>\n",
       "      <td>0.002572</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.005059</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.002171</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.867107</td>\n",
       "      <td>0.007248</td>\n",
       "      <td>0.046408</td>\n",
       "      <td>0.009956</td>\n",
       "      <td>0.206452</td>\n",
       "      <td>0.110998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444516</td>\n",
       "      <td>0.077698</td>\n",
       "      <td>0.190323</td>\n",
       "      <td>0.048279</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.433226</td>\n",
       "      <td>0.033796</td>\n",
       "      <td>0.184946</td>\n",
       "      <td>0.037496</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.429462</td>\n",
       "      <td>0.026247</td>\n",
       "      <td>0.166129</td>\n",
       "      <td>0.032499</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416290</td>\n",
       "      <td>0.022749</td>\n",
       "      <td>0.156129</td>\n",
       "      <td>0.019738</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409290</td>\n",
       "      <td>0.013817</td>\n",
       "      <td>0.149462</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.404624</td>\n",
       "      <td>0.007298</td>\n",
       "      <td>0.136406</td>\n",
       "      <td>0.010748</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.395484</td>\n",
       "      <td>0.007524</td>\n",
       "      <td>0.125806</td>\n",
       "      <td>0.010008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.388065</td>\n",
       "      <td>0.007005</td>\n",
       "      <td>0.124014</td>\n",
       "      <td>0.011012</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.386810</td>\n",
       "      <td>0.007709</td>\n",
       "      <td>0.117909</td>\n",
       "      <td>0.011962</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.382536</td>\n",
       "      <td>0.008373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>0.995236</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.065333</td>\n",
       "      <td>0.006025</td>\n",
       "      <td>0.086338</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.074335</td>\n",
       "      <td>0.006675</td>\n",
       "      <td>0.004764</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.541796</td>\n",
       "      <td>0.004098</td>\n",
       "      <td>0.007707</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.058065</td>\n",
       "      <td>0.024140</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.340645</td>\n",
       "      <td>0.016898</td>\n",
       "      <td>0.058065</td>\n",
       "      <td>0.016448</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.340645</td>\n",
       "      <td>0.011514</td>\n",
       "      <td>0.073118</td>\n",
       "      <td>0.012540</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.351183</td>\n",
       "      <td>0.008778</td>\n",
       "      <td>0.066129</td>\n",
       "      <td>0.006035</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346290</td>\n",
       "      <td>0.004224</td>\n",
       "      <td>0.060645</td>\n",
       "      <td>0.009656</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.342452</td>\n",
       "      <td>0.006759</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.008996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.345161</td>\n",
       "      <td>0.006297</td>\n",
       "      <td>0.067281</td>\n",
       "      <td>0.009927</td>\n",
       "      <td>0.999078</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.346820</td>\n",
       "      <td>0.007296</td>\n",
       "      <td>0.066129</td>\n",
       "      <td>0.009744</td>\n",
       "      <td>0.999194</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.346048</td>\n",
       "      <td>0.007074</td>\n",
       "      <td>0.068817</td>\n",
       "      <td>0.012903</td>\n",
       "      <td>0.999283</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.347957</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.070876</td>\n",
       "      <td>0.012383</td>\n",
       "      <td>0.999355</td>\n",
       "      <td>0.00129</td>\n",
       "      <td>0.349420</td>\n",
       "      <td>0.008875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.997699</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>0.002508</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.813825</td>\n",
       "      <td>0.014377</td>\n",
       "      <td>0.010584</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>0.025806</td>\n",
       "      <td>0.024140</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.318065</td>\n",
       "      <td>0.016898</td>\n",
       "      <td>0.025806</td>\n",
       "      <td>0.021878</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.318065</td>\n",
       "      <td>0.015315</td>\n",
       "      <td>0.023656</td>\n",
       "      <td>0.019710</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.316559</td>\n",
       "      <td>0.013797</td>\n",
       "      <td>0.019355</td>\n",
       "      <td>0.013103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.313548</td>\n",
       "      <td>0.009172</td>\n",
       "      <td>0.019355</td>\n",
       "      <td>0.011541</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.313548</td>\n",
       "      <td>0.008079</td>\n",
       "      <td>0.021505</td>\n",
       "      <td>0.012260</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315054</td>\n",
       "      <td>0.008582</td>\n",
       "      <td>0.024885</td>\n",
       "      <td>0.013228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317419</td>\n",
       "      <td>0.009260</td>\n",
       "      <td>0.025806</td>\n",
       "      <td>0.013398</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.318065</td>\n",
       "      <td>0.009378</td>\n",
       "      <td>0.024373</td>\n",
       "      <td>0.013101</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317061</td>\n",
       "      <td>0.009171</td>\n",
       "      <td>0.022552</td>\n",
       "      <td>0.011355</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.315786</td>\n",
       "      <td>0.007948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.027023</td>\n",
       "      <td>0.001393</td>\n",
       "      <td>0.002249</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.989688</td>\n",
       "      <td>0.004740</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.972947</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>0.507655</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.012903</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.304516</td>\n",
       "      <td>0.009032</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.302258</td>\n",
       "      <td>0.004516</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.004301</td>\n",
       "      <td>0.997849</td>\n",
       "      <td>0.004301</td>\n",
       "      <td>0.300860</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.998387</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.300645</td>\n",
       "      <td>0.001290</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>0.003161</td>\n",
       "      <td>0.99871</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>0.302323</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>0.998925</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.301935</td>\n",
       "      <td>0.001686</td>\n",
       "      <td>0.002765</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>0.999078</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.301659</td>\n",
       "      <td>0.001446</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.001975</td>\n",
       "      <td>0.999194</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.301452</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.001756</td>\n",
       "      <td>0.999283</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.301290</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.001933</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>0.999355</td>\n",
       "      <td>0.00129</td>\n",
       "      <td>0.301160</td>\n",
       "      <td>0.001010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.027023</td>\n",
       "      <td>0.001393</td>\n",
       "      <td>0.002249</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.989688</td>\n",
       "      <td>0.004740</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.972947</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>0.507655</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.012903</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.304516</td>\n",
       "      <td>0.009032</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.302258</td>\n",
       "      <td>0.004516</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.004301</td>\n",
       "      <td>0.997849</td>\n",
       "      <td>0.004301</td>\n",
       "      <td>0.300860</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.998387</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.300645</td>\n",
       "      <td>0.001290</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>0.003161</td>\n",
       "      <td>0.99871</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>0.302323</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>0.998925</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.301935</td>\n",
       "      <td>0.001686</td>\n",
       "      <td>0.002765</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>0.999078</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.301659</td>\n",
       "      <td>0.001446</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.001975</td>\n",
       "      <td>0.999194</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.301452</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.001756</td>\n",
       "      <td>0.999283</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.301290</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.001933</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>0.999355</td>\n",
       "      <td>0.00129</td>\n",
       "      <td>0.301160</td>\n",
       "      <td>0.001010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Accuracy  Accuracy_std  Precision  Precision_std    Recall  \\\n",
       "CatBoost       0.997849      0.000019   0.720836       0.072434  0.048323   \n",
       "XGB            0.997812      0.000029   0.588264       0.081948  0.040591   \n",
       "RF             0.997804      0.000006   1.000000       0.000000  0.009022   \n",
       "LR             0.997762      0.000016   0.153333       0.232475  0.002572   \n",
       "DT             0.995236      0.000134   0.065333       0.006025  0.086338   \n",
       "MultinomialNB  0.997699      0.000078   0.025000       0.050000  0.000643   \n",
       "GaussianNB     0.027023      0.001393   0.002249       0.000011  0.989688   \n",
       "BernoulliNB    0.027023      0.001393   0.002249       0.000011  0.989688   \n",
       "\n",
       "               Recall_std        F1    F1_std     Brier  Brier_std   AUC-ROC  \\\n",
       "CatBoost         0.009321  0.090337  0.016369  0.002070   0.000022  0.893919   \n",
       "XGB              0.008551  0.075843  0.015521  0.002099   0.000033  0.893664   \n",
       "RF               0.001296  0.017879  0.002550  0.002115   0.000018  0.796100   \n",
       "LR               0.003750  0.005059  0.007380  0.002171   0.000019  0.867107   \n",
       "DT               0.008222  0.074335  0.006675  0.004764   0.000134  0.541796   \n",
       "MultinomialNB    0.001286  0.001254  0.002508  0.002315   0.000069  0.813825   \n",
       "GaussianNB       0.004740  0.004487  0.000021  0.972947   0.001394  0.507655   \n",
       "BernoulliNB      0.004740  0.004487  0.000021  0.972947   0.001394  0.507655   \n",
       "\n",
       "               AUC-ROC_std    PR-AUC  PR-AUC_std     Lift1  Lift1_std  \\\n",
       "CatBoost          0.006897  0.115654    0.013396  0.606452   0.065794   \n",
       "XGB               0.005076  0.100469    0.018125  0.509677   0.087514   \n",
       "RF                0.011823  0.095216    0.011905  0.516129   0.079016   \n",
       "LR                0.007248  0.046408    0.009956  0.206452   0.110998   \n",
       "DT                0.004098  0.007707    0.000974  0.058065   0.024140   \n",
       "MultinomialNB     0.014377  0.010584    0.001597  0.025806   0.024140   \n",
       "GaussianNB        0.001576  0.002250    0.000009  0.006452   0.012903   \n",
       "BernoulliNB       0.001576  0.002250    0.000009  0.006452   0.012903   \n",
       "\n",
       "               Demotion1  Demotion1_std  Weighted1  Weighted1_std     Lift2  \\\n",
       "CatBoost             1.0            0.0   0.724516       0.046056  0.409677   \n",
       "XGB                  1.0            0.0   0.656774       0.061260  0.390323   \n",
       "RF                   1.0            0.0   0.661290       0.055311  0.351613   \n",
       "LR                   1.0            0.0   0.444516       0.077698  0.190323   \n",
       "DT                   1.0            0.0   0.340645       0.016898  0.058065   \n",
       "MultinomialNB        1.0            0.0   0.318065       0.016898  0.025806   \n",
       "GaussianNB           1.0            0.0   0.304516       0.009032  0.003226   \n",
       "BernoulliNB          1.0            0.0   0.304516       0.009032  0.003226   \n",
       "\n",
       "               Lift2_std  Demotion2  Demotion2_std  Weighted2  Weighted2_std  \\\n",
       "CatBoost        0.038978        1.0            0.0   0.586774       0.027284   \n",
       "XGB             0.065635        1.0            0.0   0.573226       0.045945   \n",
       "RF              0.044930        1.0            0.0   0.546129       0.031451   \n",
       "LR              0.048279        1.0            0.0   0.433226       0.033796   \n",
       "DT              0.016448        1.0            0.0   0.340645       0.011514   \n",
       "MultinomialNB   0.021878        1.0            0.0   0.318065       0.015315   \n",
       "GaussianNB      0.006452        1.0            0.0   0.302258       0.004516   \n",
       "BernoulliNB     0.006452        1.0            0.0   0.302258       0.004516   \n",
       "\n",
       "                  Lift3  Lift3_std  Demotion3  Demotion3_std  Weighted3  \\\n",
       "CatBoost       0.337634   0.033037   1.000000       0.000000   0.536344   \n",
       "XGB            0.303226   0.043225   1.000000       0.000000   0.512258   \n",
       "RF             0.290323   0.024520   1.000000       0.000000   0.503226   \n",
       "LR             0.184946   0.037496   1.000000       0.000000   0.429462   \n",
       "DT             0.073118   0.012540   1.000000       0.000000   0.351183   \n",
       "MultinomialNB  0.023656   0.019710   1.000000       0.000000   0.316559   \n",
       "GaussianNB     0.002151   0.004301   0.997849       0.004301   0.300860   \n",
       "BernoulliNB    0.002151   0.004301   0.997849       0.004301   0.300860   \n",
       "\n",
       "               Weighted3_std     Lift4  Lift4_std  Demotion4  Demotion4_std  \\\n",
       "CatBoost            0.023126  0.290323   0.027467   1.000000       0.000000   \n",
       "XGB                 0.030258  0.254839   0.038710   1.000000       0.000000   \n",
       "RF                  0.017164  0.248387   0.021878   1.000000       0.000000   \n",
       "LR                  0.026247  0.166129   0.032499   1.000000       0.000000   \n",
       "DT                  0.008778  0.066129   0.006035   1.000000       0.000000   \n",
       "MultinomialNB       0.013797  0.019355   0.013103   1.000000       0.000000   \n",
       "GaussianNB          0.001720  0.001613   0.003226   0.998387       0.003226   \n",
       "BernoulliNB         0.001720  0.001613   0.003226   0.998387       0.003226   \n",
       "\n",
       "               Weighted4  Weighted4_std     Lift5  Lift5_std  Demotion5  \\\n",
       "CatBoost        0.503226       0.019227  0.256774   0.026569    1.00000   \n",
       "XGB             0.478387       0.027097  0.229677   0.032796    1.00000   \n",
       "RF              0.473871       0.015315  0.230968   0.023932    1.00000   \n",
       "LR              0.416290       0.022749  0.156129   0.019738    1.00000   \n",
       "DT              0.346290       0.004224  0.060645   0.009656    1.00000   \n",
       "MultinomialNB   0.313548       0.009172  0.019355   0.011541    1.00000   \n",
       "GaussianNB      0.300645       0.001290  0.003871   0.003161    0.99871   \n",
       "BernoulliNB     0.300645       0.001290  0.003871   0.003161    0.99871   \n",
       "\n",
       "               Demotion5_std  Weighted5  Weighted5_std     Lift6  Lift6_std  \\\n",
       "CatBoost            0.000000   0.479742       0.018599  0.225806   0.028449   \n",
       "XGB                 0.000000   0.460774       0.022957  0.204301   0.023558   \n",
       "RF                  0.000000   0.461677       0.016752  0.205376   0.017471   \n",
       "LR                  0.000000   0.409290       0.013817  0.149462   0.010425   \n",
       "DT                  0.000000   0.342452       0.006759  0.064516   0.008996   \n",
       "MultinomialNB       0.000000   0.313548       0.008079  0.021505   0.012260   \n",
       "GaussianNB          0.002581   0.302323       0.002024  0.003226   0.002634   \n",
       "BernoulliNB         0.002581   0.302323       0.002024  0.003226   0.002634   \n",
       "\n",
       "               Demotion6  Demotion6_std  Weighted6  Weighted6_std     Lift7  \\\n",
       "CatBoost        1.000000       0.000000   0.458065       0.019914  0.208295   \n",
       "XGB             1.000000       0.000000   0.443011       0.016491  0.188018   \n",
       "RF              1.000000       0.000000   0.443763       0.012230  0.188018   \n",
       "LR              1.000000       0.000000   0.404624       0.007298  0.136406   \n",
       "DT              1.000000       0.000000   0.345161       0.006297  0.067281   \n",
       "MultinomialNB   1.000000       0.000000   0.315054       0.008582  0.024885   \n",
       "GaussianNB      0.998925       0.002151   0.301935       0.001686  0.002765   \n",
       "BernoulliNB     0.998925       0.002151   0.301935       0.001686  0.002765   \n",
       "\n",
       "               Lift7_std  Demotion7  Demotion7_std  Weighted7  Weighted7_std  \\\n",
       "CatBoost        0.026776   1.000000       0.000000   0.445806       0.018743   \n",
       "XGB             0.023207   1.000000       0.000000   0.431613       0.016245   \n",
       "RF              0.011437   1.000000       0.000000   0.431613       0.008006   \n",
       "LR              0.010748   1.000000       0.000000   0.395484       0.007524   \n",
       "DT              0.009927   0.999078       0.001843   0.346820       0.007296   \n",
       "MultinomialNB   0.013228   1.000000       0.000000   0.317419       0.009260   \n",
       "GaussianNB      0.002258   0.999078       0.001843   0.301659       0.001446   \n",
       "BernoulliNB     0.002258   0.999078       0.001843   0.301659       0.001446   \n",
       "\n",
       "                  Lift8  Lift8_std  Demotion8  Demotion8_std  Weighted8  \\\n",
       "CatBoost       0.195968   0.024140   1.000000       0.000000   0.437177   \n",
       "XGB            0.174194   0.019983   1.000000       0.000000   0.421935   \n",
       "RF             0.175806   0.010999   1.000000       0.000000   0.423065   \n",
       "LR             0.125806   0.010008   1.000000       0.000000   0.388065   \n",
       "DT             0.066129   0.009744   0.999194       0.001613   0.346048   \n",
       "MultinomialNB  0.025806   0.013398   1.000000       0.000000   0.318065   \n",
       "GaussianNB     0.002419   0.001975   0.999194       0.001613   0.301452   \n",
       "BernoulliNB    0.002419   0.001975   0.999194       0.001613   0.301452   \n",
       "\n",
       "               Weighted8_std     Lift9  Lift9_std  Demotion9  Demotion9_std  \\\n",
       "CatBoost            0.016898  0.182079   0.021071   1.000000       0.000000   \n",
       "XGB                 0.013988  0.164875   0.018276   1.000000       0.000000   \n",
       "RF                  0.007699  0.163441   0.014968   1.000000       0.000000   \n",
       "LR                  0.007005  0.124014   0.011012   1.000000       0.000000   \n",
       "DT                  0.007074  0.068817   0.012903   0.999283       0.001434   \n",
       "MultinomialNB       0.009378  0.024373   0.013101   1.000000       0.000000   \n",
       "GaussianNB          0.001265  0.002151   0.001756   0.999283       0.001434   \n",
       "BernoulliNB         0.001265  0.002151   0.001756   0.999283       0.001434   \n",
       "\n",
       "               Weighted9  Weighted9_std    Lift10  Lift10_std  Demotion10  \\\n",
       "CatBoost        0.427455       0.014750  0.168200    0.020452    1.000000   \n",
       "XGB             0.415412       0.012793  0.157878    0.012438    1.000000   \n",
       "RF              0.414409       0.010478  0.154656    0.014872    1.000000   \n",
       "LR              0.386810       0.007709  0.117909    0.011962    1.000000   \n",
       "DT              0.347957       0.009290  0.070876    0.012383    0.999355   \n",
       "MultinomialNB   0.317061       0.009171  0.022552    0.011355    1.000000   \n",
       "GaussianNB      0.301290       0.001124  0.001933    0.001579    0.999355   \n",
       "BernoulliNB     0.301290       0.001124  0.001933    0.001579    0.999355   \n",
       "\n",
       "               Demotion10_std  Weighted10  Weighted10_std  \n",
       "CatBoost              0.00000    0.417740        0.014317  \n",
       "XGB                   0.00000    0.410514        0.008707  \n",
       "RF                    0.00000    0.408259        0.010410  \n",
       "LR                    0.00000    0.382536        0.008373  \n",
       "DT                    0.00129    0.349420        0.008875  \n",
       "MultinomialNB         0.00000    0.315786        0.007948  \n",
       "GaussianNB            0.00129    0.301160        0.001010  \n",
       "BernoulliNB           0.00129    0.301160        0.001010  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9491ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c067ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700519\n",
      "700519\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_hidden_1</th>\n",
       "      <th>t_hidden_2</th>\n",
       "      <th>t_hidden_3</th>\n",
       "      <th>t_hidden_4</th>\n",
       "      <th>t_hidden_5</th>\n",
       "      <th>t_hidden_6</th>\n",
       "      <th>t_hidden_7</th>\n",
       "      <th>t_hidden_8</th>\n",
       "      <th>t_hidden_9</th>\n",
       "      <th>t_hidden_10</th>\n",
       "      <th>...</th>\n",
       "      <th>t_hidden_23</th>\n",
       "      <th>t_hidden_24</th>\n",
       "      <th>t_hidden_25</th>\n",
       "      <th>t_hidden_26</th>\n",
       "      <th>t_hidden_27</th>\n",
       "      <th>t_hidden_28</th>\n",
       "      <th>t_hidden_29</th>\n",
       "      <th>t_hidden_30</th>\n",
       "      <th>t_hidden_31</th>\n",
       "      <th>t_hidden_32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.408745</td>\n",
       "      <td>0.019283</td>\n",
       "      <td>0.875199</td>\n",
       "      <td>1.236878</td>\n",
       "      <td>-0.909931</td>\n",
       "      <td>1.124214</td>\n",
       "      <td>-0.485348</td>\n",
       "      <td>0.343595</td>\n",
       "      <td>0.063377</td>\n",
       "      <td>0.383679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227373</td>\n",
       "      <td>2.361559</td>\n",
       "      <td>1.938654</td>\n",
       "      <td>-0.574741</td>\n",
       "      <td>-1.066690</td>\n",
       "      <td>0.023123</td>\n",
       "      <td>-0.041047</td>\n",
       "      <td>0.218051</td>\n",
       "      <td>-1.160616</td>\n",
       "      <td>-1.216362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.261450</td>\n",
       "      <td>0.385389</td>\n",
       "      <td>0.524206</td>\n",
       "      <td>0.335333</td>\n",
       "      <td>-1.855268</td>\n",
       "      <td>0.905791</td>\n",
       "      <td>0.010550</td>\n",
       "      <td>-0.675372</td>\n",
       "      <td>1.666657</td>\n",
       "      <td>-0.492278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844264</td>\n",
       "      <td>0.836465</td>\n",
       "      <td>1.691065</td>\n",
       "      <td>0.117468</td>\n",
       "      <td>-0.533461</td>\n",
       "      <td>-0.163281</td>\n",
       "      <td>0.552240</td>\n",
       "      <td>-0.471347</td>\n",
       "      <td>-0.875878</td>\n",
       "      <td>-0.599580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.631862</td>\n",
       "      <td>1.284966</td>\n",
       "      <td>0.219037</td>\n",
       "      <td>1.735167</td>\n",
       "      <td>-0.802665</td>\n",
       "      <td>0.234240</td>\n",
       "      <td>-0.200826</td>\n",
       "      <td>0.336721</td>\n",
       "      <td>0.557764</td>\n",
       "      <td>-0.086913</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011472</td>\n",
       "      <td>2.336785</td>\n",
       "      <td>2.482246</td>\n",
       "      <td>-1.427288</td>\n",
       "      <td>-0.665344</td>\n",
       "      <td>-0.566080</td>\n",
       "      <td>-1.438796</td>\n",
       "      <td>0.712387</td>\n",
       "      <td>0.779548</td>\n",
       "      <td>-0.954446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.533879</td>\n",
       "      <td>-0.300280</td>\n",
       "      <td>0.737864</td>\n",
       "      <td>0.519675</td>\n",
       "      <td>-0.304382</td>\n",
       "      <td>1.147514</td>\n",
       "      <td>-0.642419</td>\n",
       "      <td>-0.139555</td>\n",
       "      <td>-0.968210</td>\n",
       "      <td>-0.300562</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.675597</td>\n",
       "      <td>0.869136</td>\n",
       "      <td>1.958137</td>\n",
       "      <td>-0.506930</td>\n",
       "      <td>-1.264389</td>\n",
       "      <td>-0.298342</td>\n",
       "      <td>-0.625637</td>\n",
       "      <td>-0.404670</td>\n",
       "      <td>0.399970</td>\n",
       "      <td>-0.899167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.051911</td>\n",
       "      <td>0.350452</td>\n",
       "      <td>0.194913</td>\n",
       "      <td>0.542731</td>\n",
       "      <td>0.227543</td>\n",
       "      <td>0.751633</td>\n",
       "      <td>0.859556</td>\n",
       "      <td>-1.049925</td>\n",
       "      <td>-0.084372</td>\n",
       "      <td>-0.033673</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.425382</td>\n",
       "      <td>0.602726</td>\n",
       "      <td>1.124325</td>\n",
       "      <td>0.165342</td>\n",
       "      <td>-0.799687</td>\n",
       "      <td>0.135509</td>\n",
       "      <td>-0.275075</td>\n",
       "      <td>0.080667</td>\n",
       "      <td>0.015887</td>\n",
       "      <td>0.094562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   t_hidden_1  t_hidden_2  t_hidden_3  t_hidden_4  t_hidden_5  t_hidden_6  \\\n",
       "0   -0.408745    0.019283    0.875199    1.236878   -0.909931    1.124214   \n",
       "1    1.261450    0.385389    0.524206    0.335333   -1.855268    0.905791   \n",
       "2    0.631862    1.284966    0.219037    1.735167   -0.802665    0.234240   \n",
       "3   -0.533879   -0.300280    0.737864    0.519675   -0.304382    1.147514   \n",
       "4   -1.051911    0.350452    0.194913    0.542731    0.227543    0.751633   \n",
       "\n",
       "   t_hidden_7  t_hidden_8  t_hidden_9  t_hidden_10  ...  t_hidden_23  \\\n",
       "0   -0.485348    0.343595    0.063377     0.383679  ...     0.227373   \n",
       "1    0.010550   -0.675372    1.666657    -0.492278  ...     0.844264   \n",
       "2   -0.200826    0.336721    0.557764    -0.086913  ...    -0.011472   \n",
       "3   -0.642419   -0.139555   -0.968210    -0.300562  ...    -0.675597   \n",
       "4    0.859556   -1.049925   -0.084372    -0.033673  ...    -0.425382   \n",
       "\n",
       "   t_hidden_24  t_hidden_25  t_hidden_26  t_hidden_27  t_hidden_28  \\\n",
       "0     2.361559     1.938654    -0.574741    -1.066690     0.023123   \n",
       "1     0.836465     1.691065     0.117468    -0.533461    -0.163281   \n",
       "2     2.336785     2.482246    -1.427288    -0.665344    -0.566080   \n",
       "3     0.869136     1.958137    -0.506930    -1.264389    -0.298342   \n",
       "4     0.602726     1.124325     0.165342    -0.799687     0.135509   \n",
       "\n",
       "   t_hidden_29  t_hidden_30  t_hidden_31  t_hidden_32  \n",
       "0    -0.041047     0.218051    -1.160616    -1.216362  \n",
       "1     0.552240    -0.471347    -0.875878    -0.599580  \n",
       "2    -1.438796     0.712387     0.779548    -0.954446  \n",
       "3    -0.625637    -0.404670     0.399970    -0.899167  \n",
       "4    -0.275075     0.080667     0.015887     0.094562  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df))\n",
    "df = df.drop_duplicates()\n",
    "print(len(df))\n",
    "encodings = pd.read_csv('autoencoder_classifier_loss_encoded.csv')\n",
    "if \"auto_loss\" in encodings:\n",
    "    encodings = encodings.drop(['auto_loss'], axis=1)\n",
    "encodings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aebde5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700519\n",
      "700519\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT(consumptions)</th>\n",
       "      <th>MAX(consumptions.CSS_MS_HS_USE)</th>\n",
       "      <th>MEAN(consumptions.CSS_MS_HS_USE)</th>\n",
       "      <th>MIN(consumptions.CSS_MS_HS_USE)</th>\n",
       "      <th>NUM_UNIQUE(consumptions.BS_RATE)</th>\n",
       "      <th>NUM_UNIQUE(consumptions.MS_METER_NBR)</th>\n",
       "      <th>SKEW(consumptions.CSS_MS_HS_USE)</th>\n",
       "      <th>STD(consumptions.CSS_MS_HS_USE)</th>\n",
       "      <th>SUM(consumptions.CSS_MS_HS_USE)</th>\n",
       "      <th>MODE(consumptions.DAY(MEASUREMENT_DATE))</th>\n",
       "      <th>...</th>\n",
       "      <th>t_hidden_23</th>\n",
       "      <th>t_hidden_24</th>\n",
       "      <th>t_hidden_25</th>\n",
       "      <th>t_hidden_26</th>\n",
       "      <th>t_hidden_27</th>\n",
       "      <th>t_hidden_28</th>\n",
       "      <th>t_hidden_29</th>\n",
       "      <th>t_hidden_30</th>\n",
       "      <th>t_hidden_31</th>\n",
       "      <th>t_hidden_32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>64.250000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.758461</td>\n",
       "      <td>54.389797</td>\n",
       "      <td>257.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227373</td>\n",
       "      <td>2.361559</td>\n",
       "      <td>1.938654</td>\n",
       "      <td>-0.574741</td>\n",
       "      <td>-1.066690</td>\n",
       "      <td>0.023123</td>\n",
       "      <td>-0.041047</td>\n",
       "      <td>0.218051</td>\n",
       "      <td>-1.160616</td>\n",
       "      <td>-1.216362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>51.900000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.783315</td>\n",
       "      <td>43.072162</td>\n",
       "      <td>519.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844264</td>\n",
       "      <td>0.836465</td>\n",
       "      <td>1.691065</td>\n",
       "      <td>0.117468</td>\n",
       "      <td>-0.533461</td>\n",
       "      <td>-0.163281</td>\n",
       "      <td>0.552240</td>\n",
       "      <td>-0.471347</td>\n",
       "      <td>-0.875878</td>\n",
       "      <td>-0.599580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>6068.0</td>\n",
       "      <td>3924.166667</td>\n",
       "      <td>2446.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.574519</td>\n",
       "      <td>1012.516472</td>\n",
       "      <td>47090.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011472</td>\n",
       "      <td>2.336785</td>\n",
       "      <td>2.482246</td>\n",
       "      <td>-1.427288</td>\n",
       "      <td>-0.665344</td>\n",
       "      <td>-0.566080</td>\n",
       "      <td>-1.438796</td>\n",
       "      <td>0.712387</td>\n",
       "      <td>0.779548</td>\n",
       "      <td>-0.954446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1061.0</td>\n",
       "      <td>479.333333</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020392</td>\n",
       "      <td>409.340282</td>\n",
       "      <td>2876.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.675597</td>\n",
       "      <td>0.869136</td>\n",
       "      <td>1.958137</td>\n",
       "      <td>-0.506930</td>\n",
       "      <td>-1.264389</td>\n",
       "      <td>-0.298342</td>\n",
       "      <td>-0.625637</td>\n",
       "      <td>-0.404670</td>\n",
       "      <td>0.399970</td>\n",
       "      <td>-0.899167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>1247.0</td>\n",
       "      <td>536.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.537625</td>\n",
       "      <td>335.364392</td>\n",
       "      <td>12884.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.425382</td>\n",
       "      <td>0.602726</td>\n",
       "      <td>1.124325</td>\n",
       "      <td>0.165342</td>\n",
       "      <td>-0.799687</td>\n",
       "      <td>0.135509</td>\n",
       "      <td>-0.275075</td>\n",
       "      <td>0.080667</td>\n",
       "      <td>0.015887</td>\n",
       "      <td>0.094562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   COUNT(consumptions)  MAX(consumptions.CSS_MS_HS_USE)  \\\n",
       "0                  4.0                            135.0   \n",
       "1                 10.0                            127.0   \n",
       "2                 12.0                           6068.0   \n",
       "3                  6.0                           1061.0   \n",
       "4                 24.0                           1247.0   \n",
       "\n",
       "   MEAN(consumptions.CSS_MS_HS_USE)  MIN(consumptions.CSS_MS_HS_USE)  \\\n",
       "0                         64.250000                             12.0   \n",
       "1                         51.900000                              0.0   \n",
       "2                       3924.166667                           2446.0   \n",
       "3                        479.333333                              7.0   \n",
       "4                        536.833333                              0.0   \n",
       "\n",
       "   NUM_UNIQUE(consumptions.BS_RATE)  NUM_UNIQUE(consumptions.MS_METER_NBR)  \\\n",
       "0                               1.0                                    1.0   \n",
       "1                               1.0                                    2.0   \n",
       "2                               1.0                                    1.0   \n",
       "3                               2.0                                    1.0   \n",
       "4                               2.0                                    1.0   \n",
       "\n",
       "   SKEW(consumptions.CSS_MS_HS_USE)  STD(consumptions.CSS_MS_HS_USE)  \\\n",
       "0                          0.758461                        54.389797   \n",
       "1                          0.783315                        43.072162   \n",
       "2                          0.574519                      1012.516472   \n",
       "3                          0.020392                       409.340282   \n",
       "4                          0.537625                       335.364392   \n",
       "\n",
       "   SUM(consumptions.CSS_MS_HS_USE)  MODE(consumptions.DAY(MEASUREMENT_DATE))  \\\n",
       "0                            257.0                                       2.0   \n",
       "1                            519.0                                       2.0   \n",
       "2                          47090.0                                      28.0   \n",
       "3                           2876.0                                       4.0   \n",
       "4                          12884.0                                       4.0   \n",
       "\n",
       "   ...  t_hidden_23  t_hidden_24  t_hidden_25  t_hidden_26  t_hidden_27  \\\n",
       "0  ...     0.227373     2.361559     1.938654    -0.574741    -1.066690   \n",
       "1  ...     0.844264     0.836465     1.691065     0.117468    -0.533461   \n",
       "2  ...    -0.011472     2.336785     2.482246    -1.427288    -0.665344   \n",
       "3  ...    -0.675597     0.869136     1.958137    -0.506930    -1.264389   \n",
       "4  ...    -0.425382     0.602726     1.124325     0.165342    -0.799687   \n",
       "\n",
       "   t_hidden_28  t_hidden_29  t_hidden_30  t_hidden_31  t_hidden_32  \n",
       "0     0.023123    -0.041047     0.218051    -1.160616    -1.216362  \n",
       "1    -0.163281     0.552240    -0.471347    -0.875878    -0.599580  \n",
       "2    -0.566080    -1.438796     0.712387     0.779548    -0.954446  \n",
       "3    -0.298342    -0.625637    -0.404670     0.399970    -0.899167  \n",
       "4     0.135509    -0.275075     0.080667     0.015887     0.094562  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "encodings.reset_index(drop=True, inplace=True)\n",
    "df = df.join(encodings)\n",
    "print(len(df))\n",
    "df = df.drop_duplicates()\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0926a4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 700519\n",
      "Data bins: [698967   1552]\n",
      "Classifier: GaussianNB\n",
      "Average - Accuracy: 0.0273, Precision: 0.0023, Recall: 0.9903, F1: 0.0045, Brier: 0.9726, AUC-ROC: 0.5084, PR-AUC: 0.0023, Lift: 0.0032, Demotion: 1.0000, Weighted: 0.3023\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classifier: BernoulliNB\n",
      "Average - Accuracy: 0.0273, Precision: 0.0023, Recall: 0.9903, F1: 0.0045, Brier: 0.9726, AUC-ROC: 0.5084, PR-AUC: 0.0023, Lift: 0.0032, Demotion: 1.0000, Weighted: 0.3023\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classifier: MultinomialNB\n",
      "Average - Accuracy: 0.9976, Precision: 0.0446, Recall: 0.0026, F1: 0.0049, Brier: 0.0024, AUC-ROC: 0.8229, PR-AUC: 0.0116, Lift: 0.0226, Demotion: 1.0000, Weighted: 0.3158\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classifier: DT\n",
      "Average - Accuracy: 0.9954, Precision: 0.0782, Recall: 0.1012, F1: 0.0881, Brier: 0.0046, AUC-ROC: 0.5493, PR-AUC: 0.0099, Lift: 0.0694, Demotion: 1.0000, Weighted: 0.3485\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classifier: RF\n",
      "Average - Accuracy: 0.9979, Precision: 0.8344, Recall: 0.0483, F1: 0.0909, Brier: 0.0021, AUC-ROC: 0.8002, PR-AUC: 0.1358, Lift: 0.3290, Demotion: 1.0000, Weighted: 0.5303\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classifier: LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vasilis/miniconda3/envs/HendoChallenge/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/vasilis/miniconda3/envs/HendoChallenge/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/vasilis/miniconda3/envs/HendoChallenge/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/vasilis/miniconda3/envs/HendoChallenge/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/vasilis/miniconda3/envs/HendoChallenge/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average - Accuracy: 0.9978, Precision: 0.4176, Recall: 0.0122, F1: 0.0237, Brier: 0.0021, AUC-ROC: 0.8876, PR-AUC: 0.0683, Lift: 0.1887, Demotion: 1.0000, Weighted: 0.4321\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classifier: CatBoost\n",
      "Average - Accuracy: 0.9979, Precision: 0.6923, Recall: 0.0735, F1: 0.1321, Brier: 0.0020, AUC-ROC: 0.9038, PR-AUC: 0.1429, Lift: 0.3468, Demotion: 1.0000, Weighted: 0.5427\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['target'], axis=1)\n",
    "y = df['target']\n",
    "results2 = train(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a48033d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Accuracy_std</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Precision_std</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Recall_std</th>\n",
       "      <th>F1</th>\n",
       "      <th>F1_std</th>\n",
       "      <th>Brier</th>\n",
       "      <th>Brier_std</th>\n",
       "      <th>AUC-ROC</th>\n",
       "      <th>AUC-ROC_std</th>\n",
       "      <th>PR-AUC</th>\n",
       "      <th>PR-AUC_std</th>\n",
       "      <th>Lift1</th>\n",
       "      <th>Lift1_std</th>\n",
       "      <th>Demotion1</th>\n",
       "      <th>Demotion1_std</th>\n",
       "      <th>Weighted1</th>\n",
       "      <th>Weighted1_std</th>\n",
       "      <th>Lift2</th>\n",
       "      <th>Lift2_std</th>\n",
       "      <th>Demotion2</th>\n",
       "      <th>Demotion2_std</th>\n",
       "      <th>Weighted2</th>\n",
       "      <th>Weighted2_std</th>\n",
       "      <th>Lift3</th>\n",
       "      <th>Lift3_std</th>\n",
       "      <th>Demotion3</th>\n",
       "      <th>Demotion3_std</th>\n",
       "      <th>Weighted3</th>\n",
       "      <th>Weighted3_std</th>\n",
       "      <th>Lift4</th>\n",
       "      <th>Lift4_std</th>\n",
       "      <th>Demotion4</th>\n",
       "      <th>Demotion4_std</th>\n",
       "      <th>Weighted4</th>\n",
       "      <th>Weighted4_std</th>\n",
       "      <th>Lift5</th>\n",
       "      <th>Lift5_std</th>\n",
       "      <th>Demotion5</th>\n",
       "      <th>Demotion5_std</th>\n",
       "      <th>Weighted5</th>\n",
       "      <th>Weighted5_std</th>\n",
       "      <th>Lift6</th>\n",
       "      <th>Lift6_std</th>\n",
       "      <th>Demotion6</th>\n",
       "      <th>Demotion6_std</th>\n",
       "      <th>Weighted6</th>\n",
       "      <th>Weighted6_std</th>\n",
       "      <th>Lift7</th>\n",
       "      <th>Lift7_std</th>\n",
       "      <th>Demotion7</th>\n",
       "      <th>Demotion7_std</th>\n",
       "      <th>Weighted7</th>\n",
       "      <th>Weighted7_std</th>\n",
       "      <th>Lift8</th>\n",
       "      <th>Lift8_std</th>\n",
       "      <th>Demotion8</th>\n",
       "      <th>Demotion8_std</th>\n",
       "      <th>Weighted8</th>\n",
       "      <th>Weighted8_std</th>\n",
       "      <th>Lift9</th>\n",
       "      <th>Lift9_std</th>\n",
       "      <th>Demotion9</th>\n",
       "      <th>Demotion9_std</th>\n",
       "      <th>Weighted9</th>\n",
       "      <th>Weighted9_std</th>\n",
       "      <th>Lift10</th>\n",
       "      <th>Lift10_std</th>\n",
       "      <th>Demotion10</th>\n",
       "      <th>Demotion10_std</th>\n",
       "      <th>Weighted10</th>\n",
       "      <th>Weighted10_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>0.997876</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.692295</td>\n",
       "      <td>0.098475</td>\n",
       "      <td>0.073457</td>\n",
       "      <td>0.021535</td>\n",
       "      <td>0.132131</td>\n",
       "      <td>0.035533</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.903834</td>\n",
       "      <td>0.007602</td>\n",
       "      <td>0.142906</td>\n",
       "      <td>0.016385</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.116129</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.801290</td>\n",
       "      <td>0.081290</td>\n",
       "      <td>0.496774</td>\n",
       "      <td>0.064838</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.647742</td>\n",
       "      <td>0.045387</td>\n",
       "      <td>0.404301</td>\n",
       "      <td>0.049789</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583011</td>\n",
       "      <td>0.034852</td>\n",
       "      <td>0.346774</td>\n",
       "      <td>0.026007</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.542742</td>\n",
       "      <td>0.018205</td>\n",
       "      <td>0.296774</td>\n",
       "      <td>0.029705</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.507742</td>\n",
       "      <td>0.020794</td>\n",
       "      <td>0.261290</td>\n",
       "      <td>0.026030</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.482903</td>\n",
       "      <td>0.018221</td>\n",
       "      <td>0.240553</td>\n",
       "      <td>0.021098</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.468387</td>\n",
       "      <td>0.014768</td>\n",
       "      <td>0.223387</td>\n",
       "      <td>0.018496</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.456371</td>\n",
       "      <td>0.012947</td>\n",
       "      <td>0.204301</td>\n",
       "      <td>0.015541</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.443011</td>\n",
       "      <td>0.010879</td>\n",
       "      <td>0.192015</td>\n",
       "      <td>0.012580</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.434411</td>\n",
       "      <td>0.008806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.997869</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.834370</td>\n",
       "      <td>0.084856</td>\n",
       "      <td>0.048327</td>\n",
       "      <td>0.013992</td>\n",
       "      <td>0.090895</td>\n",
       "      <td>0.024528</td>\n",
       "      <td>0.002055</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.800224</td>\n",
       "      <td>0.006673</td>\n",
       "      <td>0.135759</td>\n",
       "      <td>0.015638</td>\n",
       "      <td>0.748387</td>\n",
       "      <td>0.114323</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.823871</td>\n",
       "      <td>0.080026</td>\n",
       "      <td>0.519355</td>\n",
       "      <td>0.073134</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.663548</td>\n",
       "      <td>0.051194</td>\n",
       "      <td>0.404301</td>\n",
       "      <td>0.046919</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583011</td>\n",
       "      <td>0.032843</td>\n",
       "      <td>0.329032</td>\n",
       "      <td>0.028122</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.530323</td>\n",
       "      <td>0.019685</td>\n",
       "      <td>0.285161</td>\n",
       "      <td>0.022124</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499613</td>\n",
       "      <td>0.015487</td>\n",
       "      <td>0.256989</td>\n",
       "      <td>0.017137</td>\n",
       "      <td>0.998925</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.479570</td>\n",
       "      <td>0.012194</td>\n",
       "      <td>0.233180</td>\n",
       "      <td>0.018108</td>\n",
       "      <td>0.999078</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.462949</td>\n",
       "      <td>0.012869</td>\n",
       "      <td>0.220968</td>\n",
       "      <td>0.017183</td>\n",
       "      <td>0.999194</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.454435</td>\n",
       "      <td>0.012140</td>\n",
       "      <td>0.201434</td>\n",
       "      <td>0.018050</td>\n",
       "      <td>0.999283</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.440789</td>\n",
       "      <td>0.012736</td>\n",
       "      <td>0.192022</td>\n",
       "      <td>0.017591</td>\n",
       "      <td>0.999355</td>\n",
       "      <td>0.001290</td>\n",
       "      <td>0.434222</td>\n",
       "      <td>0.012409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.997773</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.417599</td>\n",
       "      <td>0.197605</td>\n",
       "      <td>0.012237</td>\n",
       "      <td>0.005143</td>\n",
       "      <td>0.023743</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.002140</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.887571</td>\n",
       "      <td>0.007754</td>\n",
       "      <td>0.068290</td>\n",
       "      <td>0.010508</td>\n",
       "      <td>0.283871</td>\n",
       "      <td>0.094379</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.498710</td>\n",
       "      <td>0.066065</td>\n",
       "      <td>0.254839</td>\n",
       "      <td>0.044930</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.478387</td>\n",
       "      <td>0.031451</td>\n",
       "      <td>0.232258</td>\n",
       "      <td>0.032330</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.462581</td>\n",
       "      <td>0.022631</td>\n",
       "      <td>0.188710</td>\n",
       "      <td>0.025806</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.432097</td>\n",
       "      <td>0.018065</td>\n",
       "      <td>0.179355</td>\n",
       "      <td>0.021359</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.425548</td>\n",
       "      <td>0.014951</td>\n",
       "      <td>0.172043</td>\n",
       "      <td>0.019827</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420430</td>\n",
       "      <td>0.013879</td>\n",
       "      <td>0.160369</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.412258</td>\n",
       "      <td>0.011966</td>\n",
       "      <td>0.157258</td>\n",
       "      <td>0.018033</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.410081</td>\n",
       "      <td>0.012623</td>\n",
       "      <td>0.151254</td>\n",
       "      <td>0.015441</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405878</td>\n",
       "      <td>0.010809</td>\n",
       "      <td>0.144962</td>\n",
       "      <td>0.016582</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.401473</td>\n",
       "      <td>0.011608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>0.995363</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.078195</td>\n",
       "      <td>0.005833</td>\n",
       "      <td>0.101158</td>\n",
       "      <td>0.007762</td>\n",
       "      <td>0.088144</td>\n",
       "      <td>0.006216</td>\n",
       "      <td>0.004637</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.549253</td>\n",
       "      <td>0.003857</td>\n",
       "      <td>0.009935</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>0.083871</td>\n",
       "      <td>0.069486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.358710</td>\n",
       "      <td>0.048640</td>\n",
       "      <td>0.093548</td>\n",
       "      <td>0.035921</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.365484</td>\n",
       "      <td>0.025145</td>\n",
       "      <td>0.077419</td>\n",
       "      <td>0.027540</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.354194</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>0.069355</td>\n",
       "      <td>0.021398</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.348548</td>\n",
       "      <td>0.014978</td>\n",
       "      <td>0.081290</td>\n",
       "      <td>0.019398</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.356903</td>\n",
       "      <td>0.013578</td>\n",
       "      <td>0.081720</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.357204</td>\n",
       "      <td>0.010210</td>\n",
       "      <td>0.081106</td>\n",
       "      <td>0.011875</td>\n",
       "      <td>0.999078</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.356498</td>\n",
       "      <td>0.008070</td>\n",
       "      <td>0.080645</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>0.999194</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.356210</td>\n",
       "      <td>0.005544</td>\n",
       "      <td>0.077419</td>\n",
       "      <td>0.007024</td>\n",
       "      <td>0.999283</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.353978</td>\n",
       "      <td>0.004891</td>\n",
       "      <td>0.079898</td>\n",
       "      <td>0.002456</td>\n",
       "      <td>0.999355</td>\n",
       "      <td>0.001290</td>\n",
       "      <td>0.355735</td>\n",
       "      <td>0.001944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.997613</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.044551</td>\n",
       "      <td>0.036997</td>\n",
       "      <td>0.002579</td>\n",
       "      <td>0.002413</td>\n",
       "      <td>0.004857</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.002444</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.822901</td>\n",
       "      <td>0.014523</td>\n",
       "      <td>0.011648</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>0.038710</td>\n",
       "      <td>0.037619</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.327097</td>\n",
       "      <td>0.026333</td>\n",
       "      <td>0.029032</td>\n",
       "      <td>0.023705</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.320323</td>\n",
       "      <td>0.016593</td>\n",
       "      <td>0.023656</td>\n",
       "      <td>0.015803</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.316559</td>\n",
       "      <td>0.011062</td>\n",
       "      <td>0.022581</td>\n",
       "      <td>0.017221</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.315806</td>\n",
       "      <td>0.012055</td>\n",
       "      <td>0.023226</td>\n",
       "      <td>0.011966</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.316258</td>\n",
       "      <td>0.008376</td>\n",
       "      <td>0.022581</td>\n",
       "      <td>0.012447</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315806</td>\n",
       "      <td>0.008713</td>\n",
       "      <td>0.024885</td>\n",
       "      <td>0.011875</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317419</td>\n",
       "      <td>0.008312</td>\n",
       "      <td>0.023387</td>\n",
       "      <td>0.011797</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.316371</td>\n",
       "      <td>0.008258</td>\n",
       "      <td>0.021505</td>\n",
       "      <td>0.010872</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315054</td>\n",
       "      <td>0.007610</td>\n",
       "      <td>0.020618</td>\n",
       "      <td>0.009907</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.314433</td>\n",
       "      <td>0.006935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.027350</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.002251</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.990333</td>\n",
       "      <td>0.004077</td>\n",
       "      <td>0.004491</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.972611</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>0.508423</td>\n",
       "      <td>0.002050</td>\n",
       "      <td>0.002253</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.012903</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.304516</td>\n",
       "      <td>0.009032</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.007902</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.304516</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>0.004301</td>\n",
       "      <td>0.005268</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.303011</td>\n",
       "      <td>0.003687</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.003951</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.302258</td>\n",
       "      <td>0.002766</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>0.003161</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.301806</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>0.998925</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.301183</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>0.002765</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>0.999078</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.301659</td>\n",
       "      <td>0.001968</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.001975</td>\n",
       "      <td>0.999194</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.301452</td>\n",
       "      <td>0.001722</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.001756</td>\n",
       "      <td>0.999283</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.301290</td>\n",
       "      <td>0.001531</td>\n",
       "      <td>0.002579</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.999357</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>0.301612</td>\n",
       "      <td>0.001288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.027350</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.002251</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.990333</td>\n",
       "      <td>0.004077</td>\n",
       "      <td>0.004491</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.972611</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>0.508423</td>\n",
       "      <td>0.002050</td>\n",
       "      <td>0.002253</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.012903</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.304516</td>\n",
       "      <td>0.009032</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.007902</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.304516</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>0.004301</td>\n",
       "      <td>0.005268</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.303011</td>\n",
       "      <td>0.003687</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.003951</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.302258</td>\n",
       "      <td>0.002766</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>0.003161</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.301806</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>0.998925</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.301183</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>0.002765</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>0.999078</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.301659</td>\n",
       "      <td>0.001968</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.001975</td>\n",
       "      <td>0.999194</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.301452</td>\n",
       "      <td>0.001722</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.001756</td>\n",
       "      <td>0.999283</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.301290</td>\n",
       "      <td>0.001531</td>\n",
       "      <td>0.002579</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.999357</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>0.301612</td>\n",
       "      <td>0.001288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Accuracy  Accuracy_std  Precision  Precision_std    Recall  \\\n",
       "CatBoost       0.997876      0.000050   0.692295       0.098475  0.073457   \n",
       "RF             0.997869      0.000026   0.834370       0.084856  0.048327   \n",
       "LR             0.997773      0.000022   0.417599       0.197605  0.012237   \n",
       "DT             0.995363      0.000138   0.078195       0.005833  0.101158   \n",
       "MultinomialNB  0.997613      0.000115   0.044551       0.036997  0.002579   \n",
       "GaussianNB     0.027350      0.001425   0.002251       0.000010  0.990333   \n",
       "BernoulliNB    0.027350      0.001425   0.002251       0.000010  0.990333   \n",
       "\n",
       "               Recall_std        F1    F1_std     Brier  Brier_std   AUC-ROC  \\\n",
       "CatBoost         0.021535  0.132131  0.035533  0.002032   0.000032  0.903834   \n",
       "RF               0.013992  0.090895  0.024528  0.002055   0.000023  0.800224   \n",
       "LR               0.005143  0.023743  0.010000  0.002140   0.000017  0.887571   \n",
       "DT               0.007762  0.088144  0.006216  0.004637   0.000138  0.549253   \n",
       "MultinomialNB    0.002413  0.004857  0.004500  0.002444   0.000095  0.822901   \n",
       "GaussianNB       0.004077  0.004491  0.000019  0.972611   0.001417  0.508423   \n",
       "BernoulliNB      0.004077  0.004491  0.000019  0.972611   0.001417  0.508423   \n",
       "\n",
       "               AUC-ROC_std    PR-AUC  PR-AUC_std     Lift1  Lift1_std  \\\n",
       "CatBoost          0.007602  0.142906    0.016385  0.716129   0.116129   \n",
       "RF                0.006673  0.135759    0.015638  0.748387   0.114323   \n",
       "LR                0.007754  0.068290    0.010508  0.283871   0.094379   \n",
       "DT                0.003857  0.009935    0.001069  0.083871   0.069486   \n",
       "MultinomialNB     0.014523  0.011648    0.001850  0.038710   0.037619   \n",
       "GaussianNB        0.002050  0.002253    0.000011  0.006452   0.012903   \n",
       "BernoulliNB       0.002050  0.002253    0.000011  0.006452   0.012903   \n",
       "\n",
       "               Demotion1  Demotion1_std  Weighted1  Weighted1_std     Lift2  \\\n",
       "CatBoost             1.0            0.0   0.801290       0.081290  0.496774   \n",
       "RF                   1.0            0.0   0.823871       0.080026  0.519355   \n",
       "LR                   1.0            0.0   0.498710       0.066065  0.254839   \n",
       "DT                   1.0            0.0   0.358710       0.048640  0.093548   \n",
       "MultinomialNB        1.0            0.0   0.327097       0.026333  0.029032   \n",
       "GaussianNB           1.0            0.0   0.304516       0.009032  0.006452   \n",
       "BernoulliNB          1.0            0.0   0.304516       0.009032  0.006452   \n",
       "\n",
       "               Lift2_std  Demotion2  Demotion2_std  Weighted2  Weighted2_std  \\\n",
       "CatBoost        0.064838        1.0            0.0   0.647742       0.045387   \n",
       "RF              0.073134        1.0            0.0   0.663548       0.051194   \n",
       "LR              0.044930        1.0            0.0   0.478387       0.031451   \n",
       "DT              0.035921        1.0            0.0   0.365484       0.025145   \n",
       "MultinomialNB   0.023705        1.0            0.0   0.320323       0.016593   \n",
       "GaussianNB      0.007902        1.0            0.0   0.304516       0.005531   \n",
       "BernoulliNB     0.007902        1.0            0.0   0.304516       0.005531   \n",
       "\n",
       "                  Lift3  Lift3_std  Demotion3  Demotion3_std  Weighted3  \\\n",
       "CatBoost       0.404301   0.049789        1.0            0.0   0.583011   \n",
       "RF             0.404301   0.046919        1.0            0.0   0.583011   \n",
       "LR             0.232258   0.032330        1.0            0.0   0.462581   \n",
       "DT             0.077419   0.027540        1.0            0.0   0.354194   \n",
       "MultinomialNB  0.023656   0.015803        1.0            0.0   0.316559   \n",
       "GaussianNB     0.004301   0.005268        1.0            0.0   0.303011   \n",
       "BernoulliNB    0.004301   0.005268        1.0            0.0   0.303011   \n",
       "\n",
       "               Weighted3_std     Lift4  Lift4_std  Demotion4  Demotion4_std  \\\n",
       "CatBoost            0.034852  0.346774   0.026007        1.0            0.0   \n",
       "RF                  0.032843  0.329032   0.028122        1.0            0.0   \n",
       "LR                  0.022631  0.188710   0.025806        1.0            0.0   \n",
       "DT                  0.019278  0.069355   0.021398        1.0            0.0   \n",
       "MultinomialNB       0.011062  0.022581   0.017221        1.0            0.0   \n",
       "GaussianNB          0.003687  0.003226   0.003951        1.0            0.0   \n",
       "BernoulliNB         0.003687  0.003226   0.003951        1.0            0.0   \n",
       "\n",
       "               Weighted4  Weighted4_std     Lift5  Lift5_std  Demotion5  \\\n",
       "CatBoost        0.542742       0.018205  0.296774   0.029705        1.0   \n",
       "RF              0.530323       0.019685  0.285161   0.022124        1.0   \n",
       "LR              0.432097       0.018065  0.179355   0.021359        1.0   \n",
       "DT              0.348548       0.014978  0.081290   0.019398        1.0   \n",
       "MultinomialNB   0.315806       0.012055  0.023226   0.011966        1.0   \n",
       "GaussianNB      0.302258       0.002766  0.002581   0.003161        1.0   \n",
       "BernoulliNB     0.302258       0.002766  0.002581   0.003161        1.0   \n",
       "\n",
       "               Demotion5_std  Weighted5  Weighted5_std     Lift6  Lift6_std  \\\n",
       "CatBoost                 0.0   0.507742       0.020794  0.261290   0.026030   \n",
       "RF                       0.0   0.499613       0.015487  0.256989   0.017137   \n",
       "LR                       0.0   0.425548       0.014951  0.172043   0.019827   \n",
       "DT                       0.0   0.356903       0.013578  0.081720   0.014586   \n",
       "MultinomialNB            0.0   0.316258       0.008376  0.022581   0.012447   \n",
       "GaussianNB               0.0   0.301806       0.002212  0.002151   0.002634   \n",
       "BernoulliNB              0.0   0.301806       0.002212  0.002151   0.002634   \n",
       "\n",
       "               Demotion6  Demotion6_std  Weighted6  Weighted6_std     Lift7  \\\n",
       "CatBoost        1.000000       0.000000   0.482903       0.018221  0.240553   \n",
       "RF              0.998925       0.002151   0.479570       0.012194  0.233180   \n",
       "LR              1.000000       0.000000   0.420430       0.013879  0.160369   \n",
       "DT              1.000000       0.000000   0.357204       0.010210  0.081106   \n",
       "MultinomialNB   1.000000       0.000000   0.315806       0.008713  0.024885   \n",
       "GaussianNB      0.998925       0.002151   0.301183       0.002188  0.002765   \n",
       "BernoulliNB     0.998925       0.002151   0.301183       0.002188  0.002765   \n",
       "\n",
       "               Lift7_std  Demotion7  Demotion7_std  Weighted7  Weighted7_std  \\\n",
       "CatBoost        0.021098   1.000000       0.000000   0.468387       0.014768   \n",
       "RF              0.018108   0.999078       0.001843   0.462949       0.012869   \n",
       "LR              0.017094   1.000000       0.000000   0.412258       0.011966   \n",
       "DT              0.011875   0.999078       0.001843   0.356498       0.008070   \n",
       "MultinomialNB   0.011875   1.000000       0.000000   0.317419       0.008312   \n",
       "GaussianNB      0.002258   0.999078       0.001843   0.301659       0.001968   \n",
       "BernoulliNB     0.002258   0.999078       0.001843   0.301659       0.001968   \n",
       "\n",
       "                  Lift8  Lift8_std  Demotion8  Demotion8_std  Weighted8  \\\n",
       "CatBoost       0.223387   0.018496   1.000000       0.000000   0.456371   \n",
       "RF             0.220968   0.017183   0.999194       0.001613   0.454435   \n",
       "LR             0.157258   0.018033   1.000000       0.000000   0.410081   \n",
       "DT             0.080645   0.008065   0.999194       0.001613   0.356210   \n",
       "MultinomialNB  0.023387   0.011797   1.000000       0.000000   0.316371   \n",
       "GaussianNB     0.002419   0.001975   0.999194       0.001613   0.301452   \n",
       "BernoulliNB    0.002419   0.001975   0.999194       0.001613   0.301452   \n",
       "\n",
       "               Weighted8_std     Lift9  Lift9_std  Demotion9  Demotion9_std  \\\n",
       "CatBoost            0.012947  0.204301   0.015541   1.000000       0.000000   \n",
       "RF                  0.012140  0.201434   0.018050   0.999283       0.001434   \n",
       "LR                  0.012623  0.151254   0.015441   1.000000       0.000000   \n",
       "DT                  0.005544  0.077419   0.007024   0.999283       0.001434   \n",
       "MultinomialNB       0.008258  0.021505   0.010872   1.000000       0.000000   \n",
       "GaussianNB          0.001722  0.002151   0.001756   0.999283       0.001434   \n",
       "BernoulliNB         0.001722  0.002151   0.001756   0.999283       0.001434   \n",
       "\n",
       "               Weighted9  Weighted9_std    Lift10  Lift10_std  Demotion10  \\\n",
       "CatBoost        0.443011       0.010879  0.192015    0.012580    1.000000   \n",
       "RF              0.440789       0.012736  0.192022    0.017591    0.999355   \n",
       "LR              0.405878       0.010809  0.144962    0.016582    1.000000   \n",
       "DT              0.353978       0.004891  0.079898    0.002456    0.999355   \n",
       "MultinomialNB   0.315054       0.007610  0.020618    0.009907    1.000000   \n",
       "GaussianNB      0.301290       0.001531  0.002579    0.001289    0.999357   \n",
       "BernoulliNB     0.301290       0.001531  0.002579    0.001289    0.999357   \n",
       "\n",
       "               Demotion10_std  Weighted10  Weighted10_std  \n",
       "CatBoost             0.000000    0.434411        0.008806  \n",
       "RF                   0.001290    0.434222        0.012409  \n",
       "LR                   0.000000    0.401473        0.011608  \n",
       "DT                   0.001290    0.355735        0.001944  \n",
       "MultinomialNB        0.000000    0.314433        0.006935  \n",
       "GaussianNB           0.001286    0.301612        0.001288  \n",
       "BernoulliNB          0.001286    0.301612        0.001288  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2 = results2.sort_values(['Weighted4', 'Weighted4_std'], ascending=False)\n",
    "results2.to_csv(\"classifier_res2.csv\", index=True)\n",
    "results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbbc210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3101478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = df.copy()\n",
    "tmp_df = df[['t_hidden_1', 't_hidden_2', 't_hidden_3', 't_hidden_4',\n",
    "          't_hidden_5', 't_hidden_6', 't_hidden_7', 't_hidden_8',\n",
    "          't_hidden_9', 't_hidden_10', 't_hidden_11', 't_hidden_12',\n",
    "          't_hidden_13', 't_hidden_14', 't_hidden_15', 't_hidden_16',\n",
    "          't_hidden_17', 't_hidden_18', 't_hidden_19', 't_hidden_20',\n",
    "          't_hidden_21', 't_hidden_22', 't_hidden_23', 't_hidden_24',\n",
    "          't_hidden_25', 't_hidden_26', 't_hidden_27', 't_hidden_28',\n",
    "          't_hidden_29', 't_hidden_30', 't_hidden_31', 't_hidden_32',\n",
    "            'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6117ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 700519\n",
      "Data bins: [698967   1552]\n",
      "Classifier: GaussianNB\n",
      "Average - Accuracy: 0.9250, Precision: 0.0175, Recall: 0.5967, F1: 0.0341, Brier: 0.0684, AUC-ROC: 0.8951, PR-AUC: 0.0293, Lift: 0.0839, Demotion: 1.0000, Weighted: 0.3587\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classifier: BernoulliNB\n",
      "Average - Accuracy: 0.9250, Precision: 0.0175, Recall: 0.5967, F1: 0.0341, Brier: 0.0684, AUC-ROC: 0.8951, PR-AUC: 0.0293, Lift: 0.0839, Demotion: 1.0000, Weighted: 0.3587\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classifier: MultinomialNB\n",
      "Average - Accuracy: 0.9978, Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Brier: 0.0022, AUC-ROC: 0.8535, PR-AUC: 0.0148, Lift: 0.0306, Demotion: 1.0000, Weighted: 0.3215\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classifier: DT\n",
      "Average - Accuracy: 0.9955, Precision: 0.0830, Recall: 0.1031, F1: 0.0919, Brier: 0.0045, AUC-ROC: 0.5503, PR-AUC: 0.0106, Lift: 0.0855, Demotion: 1.0000, Weighted: 0.3598\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classifier: RF\n",
      "Average - Accuracy: 0.9979, Precision: 0.8259, Recall: 0.0612, F1: 0.1134, Brier: 0.0021, AUC-ROC: 0.7899, PR-AUC: 0.1356, Lift: 0.3323, Demotion: 1.0000, Weighted: 0.5326\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classifier: LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vasilis/miniconda3/envs/HendoChallenge/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/vasilis/miniconda3/envs/HendoChallenge/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/vasilis/miniconda3/envs/HendoChallenge/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average - Accuracy: 0.9978, Precision: 0.3500, Recall: 0.0045, F1: 0.0088, Brier: 0.0022, AUC-ROC: 0.8855, PR-AUC: 0.0585, Lift: 0.1710, Demotion: 1.0000, Weighted: 0.4197\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classifier: CatBoost\n",
      "Average - Accuracy: 0.9979, Precision: 0.6864, Recall: 0.0709, F1: 0.1276, Brier: 0.0021, AUC-ROC: 0.8849, PR-AUC: 0.1274, Lift: 0.3081, Demotion: 1.0000, Weighted: 0.5156\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "X = tmp_df.drop(['target'], axis=1)\n",
    "y = tmp_df['target']\n",
    "results3 = train(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a6a5536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Accuracy_std</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Precision_std</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Recall_std</th>\n",
       "      <th>F1</th>\n",
       "      <th>F1_std</th>\n",
       "      <th>Brier</th>\n",
       "      <th>Brier_std</th>\n",
       "      <th>AUC-ROC</th>\n",
       "      <th>AUC-ROC_std</th>\n",
       "      <th>PR-AUC</th>\n",
       "      <th>PR-AUC_std</th>\n",
       "      <th>Lift1</th>\n",
       "      <th>Lift1_std</th>\n",
       "      <th>Demotion1</th>\n",
       "      <th>Demotion1_std</th>\n",
       "      <th>Weighted1</th>\n",
       "      <th>Weighted1_std</th>\n",
       "      <th>Lift2</th>\n",
       "      <th>Lift2_std</th>\n",
       "      <th>Demotion2</th>\n",
       "      <th>Demotion2_std</th>\n",
       "      <th>Weighted2</th>\n",
       "      <th>Weighted2_std</th>\n",
       "      <th>Lift3</th>\n",
       "      <th>Lift3_std</th>\n",
       "      <th>Demotion3</th>\n",
       "      <th>Demotion3_std</th>\n",
       "      <th>Weighted3</th>\n",
       "      <th>Weighted3_std</th>\n",
       "      <th>Lift4</th>\n",
       "      <th>Lift4_std</th>\n",
       "      <th>Demotion4</th>\n",
       "      <th>Demotion4_std</th>\n",
       "      <th>Weighted4</th>\n",
       "      <th>Weighted4_std</th>\n",
       "      <th>Lift5</th>\n",
       "      <th>Lift5_std</th>\n",
       "      <th>Demotion5</th>\n",
       "      <th>Demotion5_std</th>\n",
       "      <th>Weighted5</th>\n",
       "      <th>Weighted5_std</th>\n",
       "      <th>Lift6</th>\n",
       "      <th>Lift6_std</th>\n",
       "      <th>Demotion6</th>\n",
       "      <th>Demotion6_std</th>\n",
       "      <th>Weighted6</th>\n",
       "      <th>Weighted6_std</th>\n",
       "      <th>Lift7</th>\n",
       "      <th>Lift7_std</th>\n",
       "      <th>Demotion7</th>\n",
       "      <th>Demotion7_std</th>\n",
       "      <th>Weighted7</th>\n",
       "      <th>Weighted7_std</th>\n",
       "      <th>Lift8</th>\n",
       "      <th>Lift8_std</th>\n",
       "      <th>Demotion8</th>\n",
       "      <th>Demotion8_std</th>\n",
       "      <th>Weighted8</th>\n",
       "      <th>Weighted8_std</th>\n",
       "      <th>Lift9</th>\n",
       "      <th>Lift9_std</th>\n",
       "      <th>Demotion9</th>\n",
       "      <th>Demotion9_std</th>\n",
       "      <th>Weighted9</th>\n",
       "      <th>Weighted9_std</th>\n",
       "      <th>Lift10</th>\n",
       "      <th>Lift10_std</th>\n",
       "      <th>Demotion10</th>\n",
       "      <th>Demotion10_std</th>\n",
       "      <th>Weighted10</th>\n",
       "      <th>Weighted10_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.997890</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.825859</td>\n",
       "      <td>0.098582</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.016101</td>\n",
       "      <td>0.113445</td>\n",
       "      <td>0.027377</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.789936</td>\n",
       "      <td>0.006956</td>\n",
       "      <td>0.135632</td>\n",
       "      <td>0.016663</td>\n",
       "      <td>0.748387</td>\n",
       "      <td>0.065794</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.823871</td>\n",
       "      <td>0.046056</td>\n",
       "      <td>0.541935</td>\n",
       "      <td>0.051613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.679355</td>\n",
       "      <td>0.036129</td>\n",
       "      <td>0.397849</td>\n",
       "      <td>0.035985</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.578495</td>\n",
       "      <td>0.025190</td>\n",
       "      <td>0.332258</td>\n",
       "      <td>0.026698</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.532581</td>\n",
       "      <td>0.018689</td>\n",
       "      <td>0.294194</td>\n",
       "      <td>0.029593</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.505935</td>\n",
       "      <td>0.020715</td>\n",
       "      <td>0.265591</td>\n",
       "      <td>0.025806</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.485914</td>\n",
       "      <td>0.018065</td>\n",
       "      <td>0.237788</td>\n",
       "      <td>0.020526</td>\n",
       "      <td>0.999078</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.466175</td>\n",
       "      <td>0.014601</td>\n",
       "      <td>0.216129</td>\n",
       "      <td>0.021579</td>\n",
       "      <td>0.999194</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.451048</td>\n",
       "      <td>0.015364</td>\n",
       "      <td>0.201434</td>\n",
       "      <td>0.020199</td>\n",
       "      <td>0.999283</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.440789</td>\n",
       "      <td>0.014381</td>\n",
       "      <td>0.187518</td>\n",
       "      <td>0.022242</td>\n",
       "      <td>0.999355</td>\n",
       "      <td>0.00129</td>\n",
       "      <td>0.431069</td>\n",
       "      <td>0.015773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>0.997864</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.686371</td>\n",
       "      <td>0.100081</td>\n",
       "      <td>0.070881</td>\n",
       "      <td>0.016336</td>\n",
       "      <td>0.127600</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.002055</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.884929</td>\n",
       "      <td>0.009276</td>\n",
       "      <td>0.127432</td>\n",
       "      <td>0.014062</td>\n",
       "      <td>0.683871</td>\n",
       "      <td>0.082621</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778710</td>\n",
       "      <td>0.057835</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.054934</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.038453</td>\n",
       "      <td>0.391398</td>\n",
       "      <td>0.029329</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573978</td>\n",
       "      <td>0.020531</td>\n",
       "      <td>0.308065</td>\n",
       "      <td>0.031606</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.515645</td>\n",
       "      <td>0.022124</td>\n",
       "      <td>0.265806</td>\n",
       "      <td>0.026881</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.486065</td>\n",
       "      <td>0.018817</td>\n",
       "      <td>0.229032</td>\n",
       "      <td>0.022961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460323</td>\n",
       "      <td>0.016073</td>\n",
       "      <td>0.216590</td>\n",
       "      <td>0.022387</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.015671</td>\n",
       "      <td>0.197581</td>\n",
       "      <td>0.020242</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.438306</td>\n",
       "      <td>0.014169</td>\n",
       "      <td>0.181362</td>\n",
       "      <td>0.021577</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.426953</td>\n",
       "      <td>0.015104</td>\n",
       "      <td>0.169466</td>\n",
       "      <td>0.017201</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.418626</td>\n",
       "      <td>0.012041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.997776</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.004512</td>\n",
       "      <td>0.005984</td>\n",
       "      <td>0.008767</td>\n",
       "      <td>0.011505</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.885508</td>\n",
       "      <td>0.007375</td>\n",
       "      <td>0.058489</td>\n",
       "      <td>0.011243</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.109867</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458065</td>\n",
       "      <td>0.076907</td>\n",
       "      <td>0.219355</td>\n",
       "      <td>0.050595</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.453548</td>\n",
       "      <td>0.035416</td>\n",
       "      <td>0.182796</td>\n",
       "      <td>0.039066</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.427957</td>\n",
       "      <td>0.027347</td>\n",
       "      <td>0.170968</td>\n",
       "      <td>0.025705</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.419677</td>\n",
       "      <td>0.017994</td>\n",
       "      <td>0.165161</td>\n",
       "      <td>0.019822</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.415613</td>\n",
       "      <td>0.013876</td>\n",
       "      <td>0.153763</td>\n",
       "      <td>0.015054</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.407634</td>\n",
       "      <td>0.010538</td>\n",
       "      <td>0.152995</td>\n",
       "      <td>0.017824</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.407097</td>\n",
       "      <td>0.012477</td>\n",
       "      <td>0.143548</td>\n",
       "      <td>0.016645</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400484</td>\n",
       "      <td>0.011651</td>\n",
       "      <td>0.134767</td>\n",
       "      <td>0.014621</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.394337</td>\n",
       "      <td>0.010235</td>\n",
       "      <td>0.126937</td>\n",
       "      <td>0.013942</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.388856</td>\n",
       "      <td>0.009760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>0.995485</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.082957</td>\n",
       "      <td>0.008183</td>\n",
       "      <td>0.103087</td>\n",
       "      <td>0.010536</td>\n",
       "      <td>0.091851</td>\n",
       "      <td>0.008828</td>\n",
       "      <td>0.004515</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.550277</td>\n",
       "      <td>0.005246</td>\n",
       "      <td>0.010610</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>0.070968</td>\n",
       "      <td>0.055499</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.349677</td>\n",
       "      <td>0.038849</td>\n",
       "      <td>0.080645</td>\n",
       "      <td>0.039508</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.356452</td>\n",
       "      <td>0.027656</td>\n",
       "      <td>0.081720</td>\n",
       "      <td>0.027708</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.357204</td>\n",
       "      <td>0.019395</td>\n",
       "      <td>0.085484</td>\n",
       "      <td>0.028672</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.359839</td>\n",
       "      <td>0.020070</td>\n",
       "      <td>0.091613</td>\n",
       "      <td>0.018429</td>\n",
       "      <td>0.99871</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>0.363742</td>\n",
       "      <td>0.013218</td>\n",
       "      <td>0.090323</td>\n",
       "      <td>0.018748</td>\n",
       "      <td>0.998925</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.362903</td>\n",
       "      <td>0.013576</td>\n",
       "      <td>0.089401</td>\n",
       "      <td>0.014456</td>\n",
       "      <td>0.999078</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.362304</td>\n",
       "      <td>0.010429</td>\n",
       "      <td>0.086290</td>\n",
       "      <td>0.010999</td>\n",
       "      <td>0.999194</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.360161</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>0.089606</td>\n",
       "      <td>0.009881</td>\n",
       "      <td>0.999283</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.362509</td>\n",
       "      <td>0.006930</td>\n",
       "      <td>0.086342</td>\n",
       "      <td>0.007483</td>\n",
       "      <td>0.999355</td>\n",
       "      <td>0.00129</td>\n",
       "      <td>0.360246</td>\n",
       "      <td>0.005316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.924980</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>0.017529</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>0.596675</td>\n",
       "      <td>0.026771</td>\n",
       "      <td>0.034058</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>0.068408</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>0.895074</td>\n",
       "      <td>0.008292</td>\n",
       "      <td>0.029334</td>\n",
       "      <td>0.002678</td>\n",
       "      <td>0.103226</td>\n",
       "      <td>0.062551</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372258</td>\n",
       "      <td>0.043785</td>\n",
       "      <td>0.090323</td>\n",
       "      <td>0.021878</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363226</td>\n",
       "      <td>0.015315</td>\n",
       "      <td>0.094624</td>\n",
       "      <td>0.014265</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.366237</td>\n",
       "      <td>0.009986</td>\n",
       "      <td>0.083871</td>\n",
       "      <td>0.010939</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.358710</td>\n",
       "      <td>0.007657</td>\n",
       "      <td>0.082581</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.357806</td>\n",
       "      <td>0.010058</td>\n",
       "      <td>0.080645</td>\n",
       "      <td>0.020402</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.356452</td>\n",
       "      <td>0.014281</td>\n",
       "      <td>0.078341</td>\n",
       "      <td>0.021017</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.079839</td>\n",
       "      <td>0.016008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.355887</td>\n",
       "      <td>0.011205</td>\n",
       "      <td>0.076703</td>\n",
       "      <td>0.011691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353692</td>\n",
       "      <td>0.008184</td>\n",
       "      <td>0.076662</td>\n",
       "      <td>0.011675</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.353664</td>\n",
       "      <td>0.008172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.924980</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>0.017529</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>0.596675</td>\n",
       "      <td>0.026771</td>\n",
       "      <td>0.034058</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>0.068408</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>0.895074</td>\n",
       "      <td>0.008292</td>\n",
       "      <td>0.029334</td>\n",
       "      <td>0.002678</td>\n",
       "      <td>0.103226</td>\n",
       "      <td>0.062551</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372258</td>\n",
       "      <td>0.043785</td>\n",
       "      <td>0.090323</td>\n",
       "      <td>0.021878</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363226</td>\n",
       "      <td>0.015315</td>\n",
       "      <td>0.094624</td>\n",
       "      <td>0.014265</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.366237</td>\n",
       "      <td>0.009986</td>\n",
       "      <td>0.083871</td>\n",
       "      <td>0.010939</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.358710</td>\n",
       "      <td>0.007657</td>\n",
       "      <td>0.082581</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.357806</td>\n",
       "      <td>0.010058</td>\n",
       "      <td>0.080645</td>\n",
       "      <td>0.020402</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.356452</td>\n",
       "      <td>0.014281</td>\n",
       "      <td>0.078341</td>\n",
       "      <td>0.021017</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.079839</td>\n",
       "      <td>0.016008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.355887</td>\n",
       "      <td>0.011205</td>\n",
       "      <td>0.076703</td>\n",
       "      <td>0.011691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353692</td>\n",
       "      <td>0.008184</td>\n",
       "      <td>0.076662</td>\n",
       "      <td>0.011675</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.353664</td>\n",
       "      <td>0.008172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.997784</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002210</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.853524</td>\n",
       "      <td>0.021560</td>\n",
       "      <td>0.014751</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.038710</td>\n",
       "      <td>0.037619</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.327097</td>\n",
       "      <td>0.026333</td>\n",
       "      <td>0.038710</td>\n",
       "      <td>0.040290</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.327097</td>\n",
       "      <td>0.028203</td>\n",
       "      <td>0.036559</td>\n",
       "      <td>0.036369</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.325591</td>\n",
       "      <td>0.025458</td>\n",
       "      <td>0.030645</td>\n",
       "      <td>0.030347</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321452</td>\n",
       "      <td>0.021243</td>\n",
       "      <td>0.029677</td>\n",
       "      <td>0.026632</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.320774</td>\n",
       "      <td>0.018642</td>\n",
       "      <td>0.026882</td>\n",
       "      <td>0.020961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.318817</td>\n",
       "      <td>0.014673</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.018978</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.013285</td>\n",
       "      <td>0.029839</td>\n",
       "      <td>0.017221</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.320887</td>\n",
       "      <td>0.012055</td>\n",
       "      <td>0.030108</td>\n",
       "      <td>0.015475</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321075</td>\n",
       "      <td>0.010832</td>\n",
       "      <td>0.030291</td>\n",
       "      <td>0.013012</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.321204</td>\n",
       "      <td>0.009108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Accuracy  Accuracy_std  Precision  Precision_std    Recall  \\\n",
       "RF             0.997890      0.000036   0.825859       0.098582  0.061224   \n",
       "CatBoost       0.997864      0.000033   0.686371       0.100081  0.070881   \n",
       "LR             0.997776      0.000007   0.350000       0.366667  0.004512   \n",
       "DT             0.995485      0.000163   0.082957       0.008183  0.103087   \n",
       "GaussianNB     0.924980      0.000976   0.017529       0.000936  0.596675   \n",
       "BernoulliNB    0.924980      0.000976   0.017529       0.000936  0.596675   \n",
       "MultinomialNB  0.997784      0.000003   0.000000       0.000000  0.000000   \n",
       "\n",
       "               Recall_std        F1    F1_std     Brier  Brier_std   AUC-ROC  \\\n",
       "RF               0.016101  0.113445  0.027377  0.002054   0.000026  0.789936   \n",
       "CatBoost         0.016336  0.127600  0.025991  0.002055   0.000028  0.884929   \n",
       "LR               0.005984  0.008767  0.011505  0.002164   0.000013  0.885508   \n",
       "DT               0.010536  0.091851  0.008828  0.004515   0.000163  0.550277   \n",
       "GaussianNB       0.026771  0.034058  0.001810  0.068408   0.000874  0.895074   \n",
       "BernoulliNB      0.026771  0.034058  0.001810  0.068408   0.000874  0.895074   \n",
       "MultinomialNB    0.000000  0.000000  0.000000  0.002210   0.000004  0.853524   \n",
       "\n",
       "               AUC-ROC_std    PR-AUC  PR-AUC_std     Lift1  Lift1_std  \\\n",
       "RF                0.006956  0.135632    0.016663  0.748387   0.065794   \n",
       "CatBoost          0.009276  0.127432    0.014062  0.683871   0.082621   \n",
       "LR                0.007375  0.058489    0.011243  0.225806   0.109867   \n",
       "DT                0.005246  0.010610    0.001650  0.070968   0.055499   \n",
       "GaussianNB        0.008292  0.029334    0.002678  0.103226   0.062551   \n",
       "BernoulliNB       0.008292  0.029334    0.002678  0.103226   0.062551   \n",
       "MultinomialNB     0.021560  0.014751    0.007060  0.038710   0.037619   \n",
       "\n",
       "               Demotion1  Demotion1_std  Weighted1  Weighted1_std     Lift2  \\\n",
       "RF                   1.0            0.0   0.823871       0.046056  0.541935   \n",
       "CatBoost             1.0            0.0   0.778710       0.057835  0.500000   \n",
       "LR                   1.0            0.0   0.458065       0.076907  0.219355   \n",
       "DT                   1.0            0.0   0.349677       0.038849  0.080645   \n",
       "GaussianNB           1.0            0.0   0.372258       0.043785  0.090323   \n",
       "BernoulliNB          1.0            0.0   0.372258       0.043785  0.090323   \n",
       "MultinomialNB        1.0            0.0   0.327097       0.026333  0.038710   \n",
       "\n",
       "               Lift2_std  Demotion2  Demotion2_std  Weighted2  Weighted2_std  \\\n",
       "RF              0.051613        1.0            0.0   0.679355       0.036129   \n",
       "CatBoost        0.054934        1.0            0.0   0.650000       0.038453   \n",
       "LR              0.050595        1.0            0.0   0.453548       0.035416   \n",
       "DT              0.039508        1.0            0.0   0.356452       0.027656   \n",
       "GaussianNB      0.021878        1.0            0.0   0.363226       0.015315   \n",
       "BernoulliNB     0.021878        1.0            0.0   0.363226       0.015315   \n",
       "MultinomialNB   0.040290        1.0            0.0   0.327097       0.028203   \n",
       "\n",
       "                  Lift3  Lift3_std  Demotion3  Demotion3_std  Weighted3  \\\n",
       "RF             0.397849   0.035985        1.0            0.0   0.578495   \n",
       "CatBoost       0.391398   0.029329        1.0            0.0   0.573978   \n",
       "LR             0.182796   0.039066        1.0            0.0   0.427957   \n",
       "DT             0.081720   0.027708        1.0            0.0   0.357204   \n",
       "GaussianNB     0.094624   0.014265        1.0            0.0   0.366237   \n",
       "BernoulliNB    0.094624   0.014265        1.0            0.0   0.366237   \n",
       "MultinomialNB  0.036559   0.036369        1.0            0.0   0.325591   \n",
       "\n",
       "               Weighted3_std     Lift4  Lift4_std  Demotion4  Demotion4_std  \\\n",
       "RF                  0.025190  0.332258   0.026698        1.0            0.0   \n",
       "CatBoost            0.020531  0.308065   0.031606        1.0            0.0   \n",
       "LR                  0.027347  0.170968   0.025705        1.0            0.0   \n",
       "DT                  0.019395  0.085484   0.028672        1.0            0.0   \n",
       "GaussianNB          0.009986  0.083871   0.010939        1.0            0.0   \n",
       "BernoulliNB         0.009986  0.083871   0.010939        1.0            0.0   \n",
       "MultinomialNB       0.025458  0.030645   0.030347        1.0            0.0   \n",
       "\n",
       "               Weighted4  Weighted4_std     Lift5  Lift5_std  Demotion5  \\\n",
       "RF              0.532581       0.018689  0.294194   0.029593    1.00000   \n",
       "CatBoost        0.515645       0.022124  0.265806   0.026881    1.00000   \n",
       "LR              0.419677       0.017994  0.165161   0.019822    1.00000   \n",
       "DT              0.359839       0.020070  0.091613   0.018429    0.99871   \n",
       "GaussianNB      0.358710       0.007657  0.082581   0.014368    1.00000   \n",
       "BernoulliNB     0.358710       0.007657  0.082581   0.014368    1.00000   \n",
       "MultinomialNB   0.321452       0.021243  0.029677   0.026632    1.00000   \n",
       "\n",
       "               Demotion5_std  Weighted5  Weighted5_std     Lift6  Lift6_std  \\\n",
       "RF                  0.000000   0.505935       0.020715  0.265591   0.025806   \n",
       "CatBoost            0.000000   0.486065       0.018817  0.229032   0.022961   \n",
       "LR                  0.000000   0.415613       0.013876  0.153763   0.015054   \n",
       "DT                  0.002581   0.363742       0.013218  0.090323   0.018748   \n",
       "GaussianNB          0.000000   0.357806       0.010058  0.080645   0.020402   \n",
       "BernoulliNB         0.000000   0.357806       0.010058  0.080645   0.020402   \n",
       "MultinomialNB       0.000000   0.320774       0.018642  0.026882   0.020961   \n",
       "\n",
       "               Demotion6  Demotion6_std  Weighted6  Weighted6_std     Lift7  \\\n",
       "RF              1.000000       0.000000   0.485914       0.018065  0.237788   \n",
       "CatBoost        1.000000       0.000000   0.460323       0.016073  0.216590   \n",
       "LR              1.000000       0.000000   0.407634       0.010538  0.152995   \n",
       "DT              0.998925       0.002151   0.362903       0.013576  0.089401   \n",
       "GaussianNB      1.000000       0.000000   0.356452       0.014281  0.078341   \n",
       "BernoulliNB     1.000000       0.000000   0.356452       0.014281  0.078341   \n",
       "MultinomialNB   1.000000       0.000000   0.318817       0.014673  0.028571   \n",
       "\n",
       "               Lift7_std  Demotion7  Demotion7_std  Weighted7  Weighted7_std  \\\n",
       "RF              0.020526   0.999078       0.001843   0.466175       0.014601   \n",
       "CatBoost        0.022387   1.000000       0.000000   0.451613       0.015671   \n",
       "LR              0.017824   1.000000       0.000000   0.407097       0.012477   \n",
       "DT              0.014456   0.999078       0.001843   0.362304       0.010429   \n",
       "GaussianNB      0.021017   1.000000       0.000000   0.354839       0.014712   \n",
       "BernoulliNB     0.021017   1.000000       0.000000   0.354839       0.014712   \n",
       "MultinomialNB   0.018978   1.000000       0.000000   0.320000       0.013285   \n",
       "\n",
       "                  Lift8  Lift8_std  Demotion8  Demotion8_std  Weighted8  \\\n",
       "RF             0.216129   0.021579   0.999194       0.001613   0.451048   \n",
       "CatBoost       0.197581   0.020242   1.000000       0.000000   0.438306   \n",
       "LR             0.143548   0.016645   1.000000       0.000000   0.400484   \n",
       "DT             0.086290   0.010999   0.999194       0.001613   0.360161   \n",
       "GaussianNB     0.079839   0.016008   1.000000       0.000000   0.355887   \n",
       "BernoulliNB    0.079839   0.016008   1.000000       0.000000   0.355887   \n",
       "MultinomialNB  0.029839   0.017221   1.000000       0.000000   0.320887   \n",
       "\n",
       "               Weighted8_std     Lift9  Lift9_std  Demotion9  Demotion9_std  \\\n",
       "RF                  0.015364  0.201434   0.020199   0.999283       0.001434   \n",
       "CatBoost            0.014169  0.181362   0.021577   1.000000       0.000000   \n",
       "LR                  0.011651  0.134767   0.014621   1.000000       0.000000   \n",
       "DT                  0.007924  0.089606   0.009881   0.999283       0.001434   \n",
       "GaussianNB          0.011205  0.076703   0.011691   1.000000       0.000000   \n",
       "BernoulliNB         0.011205  0.076703   0.011691   1.000000       0.000000   \n",
       "MultinomialNB       0.012055  0.030108   0.015475   1.000000       0.000000   \n",
       "\n",
       "               Weighted9  Weighted9_std    Lift10  Lift10_std  Demotion10  \\\n",
       "RF              0.440789       0.014381  0.187518    0.022242    0.999355   \n",
       "CatBoost        0.426953       0.015104  0.169466    0.017201    1.000000   \n",
       "LR              0.394337       0.010235  0.126937    0.013942    1.000000   \n",
       "DT              0.362509       0.006930  0.086342    0.007483    0.999355   \n",
       "GaussianNB      0.353692       0.008184  0.076662    0.011675    1.000000   \n",
       "BernoulliNB     0.353692       0.008184  0.076662    0.011675    1.000000   \n",
       "MultinomialNB   0.321075       0.010832  0.030291    0.013012    1.000000   \n",
       "\n",
       "               Demotion10_std  Weighted10  Weighted10_std  \n",
       "RF                    0.00129    0.431069        0.015773  \n",
       "CatBoost              0.00000    0.418626        0.012041  \n",
       "LR                    0.00000    0.388856        0.009760  \n",
       "DT                    0.00129    0.360246        0.005316  \n",
       "GaussianNB            0.00000    0.353664        0.008172  \n",
       "BernoulliNB           0.00000    0.353664        0.008172  \n",
       "MultinomialNB         0.00000    0.321204        0.009108  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "results3 = results3.sort_values(['Weighted4', 'Weighted4_std'], ascending=False)\n",
    "results3.to_csv(\"classifier_res3.csv\", index=True)\n",
    "results3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987e339d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
