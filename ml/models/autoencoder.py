from types import SimpleNamespace
from typing import Optional, List

import torch

from ml.utils.train_utils import fit, predict


class AutoEncoder(torch.nn.Module):
    """
    AutoEncoder model representation.

    Args:
        encoder (torch.nn.Module): The encoder network.
        decoder (torch.nn.Module): The decoder network.
        classifier (bool, optional): Whether to integrate a classifier after the autoencoder. Defaults to False.
        sizes (List[int], optional): A list of sizes for each layer in the classifier.
    """
    def __init__(self, encoder: torch.nn.Module, decoder: torch.nn.Module,
                 classifier: Optional[torch.nn.Module] = None):
        super(AutoEncoder, self).__init__()
        self.encoder = encoder
        self.decoder = decoder
        self.classifier = None
        if classifier is not None:
            self.classifier = classifier

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Performs forward propagation through the AutoEncoder.

        Args:
            x (torch.Tensor): The input tensor to the AutoEncoder.
        """
        z = self.encoder(x)
        x_hat = self.decoder(z, sigmoid=True)
        if self.classifier is not None:
            return self.classifier(x_hat)
        return x_hat

    def fit(self, args: SimpleNamespace) -> torch.nn.Module:
        """
        Trains the AutoEncoder using the fit function defined in train_utils.

        Args:
            args (SimpleNamespace): A dictionary of parameters for training.

        Returns:
            The trained AutoEncoder model.
        """
        model = fit(args.model, args.train_loader, args.test_loader, args.epochs,
                    args.optimizer, args.criterion, args.reconstruction, args.vae,
                    args.verbose, args.return_best, args.plot_history,
                    args.num_test_samples, args.device)
        return model

    def predict(self, args: SimpleNamespace) -> List[float]:
        """
        Makes predictions using the predict function defined in train_utils.

        Args:
            args (SimpleNamespace): A dictionary of parameters for making predictions.

        Returns:
            A list of evaluation metrics.
        """
        aux = predict(args.model, args.data_loader, args.criterion, args.reconstruction, args.num_samples, args.device)
        return aux

    def encode(self, x: torch.Tensor) -> torch.Tensor:
        """
        Returns the latent dimensions generated by the encoder.

        Args:
            x (torch.Tensor): The input tensor to the AutoEncoder.

        Returns:
            torch.Tensor: The latent representation.
        """
        with torch.no_grad():
            z = self.encoder(x)
        return z


class VariationalAutoEncoder(torch.nn.Module):
    """
    Variational AutoEncoder model representation.

    Args:
        encoder (torch.nn.Module): The encoder network.
        decoder (torch.nn.Module): The decoder network.
    """
    def __init__(self, encoder: torch.nn.Module, decoder: torch.nn.Module):
        super(VariationalAutoEncoder, self).__init__()
        self.mu = None
        self.logvar = None
        self.encoder = encoder
        self.decoder = decoder

    def reparameterize(self, mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:
        """
        Reparametrization trick for the VAE.
        """
        if self.training:
            std = torch.exp(0.5 * logvar)
            eps = torch.randn_like(std)
            return mu + eps * std
        else:
            return mu

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Performs forward propagation through the AutoEncoder.

        Args:
            x (torch.Tensor): The input tensor to the VAE.
        """
        self.mu, self.logvar = self.encoder(x)
        z = self.reparameterize(self.mu, self.logvar)
        x_hat = self.decoder(z, sigmoid=True)
        return x_hat

    def kl_loss(self) -> torch.Tensor:
        """
        Calculates the KL loss.
        """
        assert self.mu is not None and self.logvar is not None
        kl_div = -0.5 * torch.sum(1 + self.logvar - self.mu.pow(2) - self.logvar.exp())
        return kl_div

    def fit(self, args):
        """
        Trains the VAE using the fit function defined in train_utils.

        Args:
            args (SimpleNamespace): A dictionary of parameters for training.

        Returns:
            The trained VAE model.
        """
        model = fit(args.model, args.train_loader, args.test_loader, args.epochs,
                    args.optimizer, args.criterion, args.reconstruction, args.vae,
                    args.verbose, args.return_best, args.plot_history,
                    args.num_test_samples, args.device)
        return model

    def predict(self, args):
        """
        Makes predictions using the predict function defined in train_utils.

        Args:
            args (SimpleNamespace): A dictionary of parameters for making predictions.

        Returns:
            A list of evaluation metrics.
        """
        aux = predict(args.model, args.data_loader, args.criterion, args.reconstruction, args.num_samples, args.device)
        return aux

    def encode(self, x):
        """
        Returns the latent dimensions generated by the encoder.

        Args:
            x (torch.Tensor): The input tensor to the AutoEncoder.

        Returns:
            torch.Tensor: The latent representation.
        """
        with torch.no_grad():
            self.mu, self.logvar = self.encoder(x)
            z = self.reparameterize(self.mu, self.logvar)
        return z
